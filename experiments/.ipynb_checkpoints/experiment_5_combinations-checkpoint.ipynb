{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b32ce4d-112a-4c2b-814b-7925eee97ce5",
   "metadata": {},
   "source": [
    "# Experiment 5 - Combinations\n",
    "Now that we have our model capable of detecting components, let us consider as label the number of relation: we still split each abstract into sentences and label, make each possible combination between them and label each combined sentence as either *No related* or *Related*, corresponding to 0 and 1 respectively.\n",
    "\n",
    "During inference, we will use the same sampling technique that processes all the sentences that form an abstract. This time, our goal is to determine the percentage of relations between arguments' components that each abstract contains, and inspect if this information along with the percentage of components could help to build a working model that predicts the number of arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee6643c-ae6d-4d48-ad83-18f6eb1638bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Antonio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from experiment_5_code import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4b71a-b9f7-4394-ae94-5678e5c8fd67",
   "metadata": {},
   "source": [
    "### 1. Preprocessing\n",
    "Here we preprocess our data by splitting the abstracts into sentences. Each combination of two sentences is then labeled as either being a `Relationship`, labeled as `1`, or `Not relationship`, labeled as `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471b1a98-8b85-4454-bafe-31ed4ad14d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = read_brat_dataset('../data/train/neoplasm_train') + read_brat_dataset('../data/dev/neoplasm_dev')\n",
    "test_set = read_brat_dataset('../data/test/glaucoma_test') + read_brat_dataset('../data/test/neoplasm_test') + read_brat_dataset('../data/test/mixed_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a2cffa-f391-4e11-bbe0-32124242d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train set:\n",
      "\tLabel 0: 35324 samples\n",
      "\tLabel 1: 1636 samples\n",
      "\n",
      "\tThere are 2 different labels in the train set -> [0, 1]\n",
      "\tAverage number of sentences pairs per file in train set: 92\n",
      "\tMax sentence pair length: 162\n",
      "\tAverage relationships per file: 4.16\n",
      "\tAverage no relationships per file: 88.31\n",
      "\n",
      "- Test set:\n",
      "\tLabel 0: 24835 samples\n",
      "\tLabel 1: 1120 samples\n",
      "\n",
      "\tThere are 2 different labels in the test set -> [0, 1]\n",
      "\tAverage number of sentences pairs per file in test set: 96\n",
      "\tMax sentence pair length: 145\n",
      "\tAverage relationships per file: 4.23\n",
      "\tAverage no relationships per file: 92.32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_counts_train, avg_sentences_per_file_train = compute_dataset_statistics(train_set, dataset_name=\"train\")\n",
    "label_counts_test, avg_sentences_per_file_test = compute_dataset_statistics(test_set, dataset_name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b11b11-4c24-4a19-8721-f132b39f4705",
   "metadata": {},
   "source": [
    "Follows an example of what our dictionary looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb562ae9-ef26-4bce-bd30-d7c8e7fb543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_file_info(train_set, filename='16416368') \n",
    "# display_file_info(train_set, filename=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df97bf69-2965-4927-ac08-b3cdee1b6238",
   "metadata": {},
   "source": [
    "Next, we create the dataset `FilenameLabelledCollection`, which inherits from `QuaPy`'s `LabelledCollection` class. This allows us to keep track of the filenames corresponding to each abstract to which the sentences belong. The `index` method is also modified to return two `FilenameLabelledCollection` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e4d204-eea2-4378-b97d-06bc31fddfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_collection = FilenameLabelledCollection([data['sentence_pair'] for data in train_set], \n",
    "                                                 [data['label'] for data in train_set], \n",
    "                                                 [data['filename'] for data in train_set], \n",
    "                                                 classes=list(label_counts_train.keys()))\n",
    "\n",
    "test_collection = FilenameLabelledCollection([data['sentence_pair'] for data in test_set], \n",
    "                                                 [data['label'] for data in test_set], \n",
    "                                                 [data['filename'] for data in test_set], \n",
    "                                                 classes=list(label_counts_test.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae1e54e-10bd-40ed-8632-af7263a83863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|███████████████████████████████████████████████████████████████| 36960/36960 [00:01<00:00, 23797.87it/s]\n",
      "indexing: 100%|███████████████████████████████████████████████████████████████| 25955/25955 [00:00<00:00, 33018.80it/s]\n"
     ]
    }
   ],
   "source": [
    "indexer = qp.data.preprocessing.IndexTransformer(min_df=1)\n",
    "abs_dataset = Dataset(train_collection, test_collection)\n",
    "\n",
    "index(abs_dataset, indexer, inplace=True)\n",
    "\n",
    "qp.environ['SAMPLE_SIZE'] = avg_sentences_per_file_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97b60c-b816-49b5-8b56-8a0a4f499602",
   "metadata": {},
   "source": [
    "### 2. Classifier\n",
    "`QuaNet` requires a classifier that can provide embedded representations of the inputs. In the original paper, `QuaNet` was tested using an `LSTM` as the base classifier; as `QuaPy`'s authors show in their [example](https://hlt-isti.github.io/QuaPy/manuals/methods.html#the-quanet-neural-network), we will use an instantiation of `QuaNet` that employs a `CNN` as a probabilistic classifier, taking its last layer representation as the document embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9680a2-8b2f-41e7-8fd3-139ee4e96e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeuralNetwork running on cpu]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNNnet] training epoch=19 tr-loss=0.01389 tr-acc=99.56% tr-macroF1=97.36% patience=1/10 val-loss=0.47329 val-acc=94.72C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\Lib\\site-packages\\quapy\\classification\\neural.py:203: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(checkpoint))\n",
      "[CNNnet] training epoch=19 tr-loss=0.01389 tr-acc=99.56% tr-macroF1=97.36% patience=1/10 val-loss=0.47329 val-acc=94.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ended by patience exhasted; loading best model parameters in ../checkpoint/classifier_net.dat for epoch 9\n",
      "performing one training pass over the validation set...\n",
      "[done]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<quapy.classification.neural.NeuralClassifierTrainer at 0x1e32edb9bb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the text classifier:\n",
    "cnn_module = CNNnet(abs_dataset.vocabulary_size, abs_dataset.training.n_classes)\n",
    "cnn_classifier = NeuralClassifierTrainer(cnn_module, device='cpu')\n",
    "cnn_classifier.fit(*abs_dataset.training.Xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "634a48c7-e2df-4b40-a2b5-b38401810af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train set:\n",
      "\tF1: 0.4886835260915279\n",
      "\tAccuracy: 0.9557359307359308\n",
      "- Test set:\n",
      "\tF1: 0.4889742075211656\n",
      "\tAccuracy: 0.9568483914467347\n"
     ]
    }
   ],
   "source": [
    "f1_train = 1-qp.error.f1e(abs_dataset.training.labels, cnn_classifier.predict(abs_dataset.training.instances))\n",
    "accuracy_train = 1-qp.error.acce(abs_dataset.training.labels, cnn_classifier.predict(abs_dataset.training.instances))\n",
    "print('- Train set:')\n",
    "print(f'\\tF1: {f1_train}')    \n",
    "print(f'\\tAccuracy: {accuracy_train}')    \n",
    "\n",
    "f1_test = 1-qp.error.f1e(abs_dataset.test.labels, cnn_classifier.predict(abs_dataset.test.instances))\n",
    "accuracy_test = 1-qp.error.acce(abs_dataset.test.labels, cnn_classifier.predict(abs_dataset.test.instances))\n",
    "print('- Test set:')\n",
    "print(f'\\tF1: {f1_test}')    \n",
    "print(f'\\tAccuracy: {accuracy_test}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc37da-6239-4833-9c63-03cac51fdb78",
   "metadata": {},
   "source": [
    "### 3. QuaNet \n",
    "The results are solid, let's move onto `QuaNet` training phase. `QuaNet` observes the classification predictions to learn higher-order *quantification embeddings*, which are then refined by incorporating quantification predictions of simple classify-and-count-like methods.\n",
    "\n",
    "![architecture](./images/quanet_architecture.png)\n",
    "\n",
    "The QuaNet architecture (see Figure 1) consists of two main components: a **recurrent component** and a **fully connected component**.\n",
    "\n",
    "#### 3.1 Recurrent Component: Bidirectional LSTM\n",
    "- The core of the model is a **Bidirectional LSTM** (Long Short-Term Memory), a type of recurrent neural network. \n",
    "- The LSTM receives as input a **list of pairs** $⟨Pr(c|x), \\vec{x}⟩$, where:\n",
    "  - $Pr(c|x)$ is the probability that a classifier $h$ assigns class $c$ to document $x$.\n",
    "  - $\\vec{x}$ is the **document embedding**, a vector representing the document's content.\n",
    "- The list is **sorted by the value of $Pr(c|x)$**, meaning the documents are arranged from least to most likely to belong to class $c$.\n",
    "  \n",
    "The **intuition** behind this approach is that the LSTM will \"learn to count\" positive and negative examples. By observing the ordered sequence of probabilities, the LSTM should learn to recognize the point where the documents switch from negative to positive examples. The document embedding $\\vec{x}$ helps the LSTM assign different importance to each document when making its prediction.\n",
    "\n",
    "The output of the LSTM is called a **quantification embedding**—a dense vector representing the information about the quantification task learned from the input data.\n",
    "\n",
    "#### 3.2 Fully Connected Component\n",
    "- The vector returned by the LSTM is combined with additional information, specifically **quantification-related statistics**:\n",
    "  - $\\hat{p}_c^{CC}(D)$, $\\hat{p}_c^{ACC}(D)$, $\\hat{p}_c^{PCC}(D)$, and $\\hat{p}_c^{PACC}(D)$, which are quantification predictions from different methods.\n",
    "  - $tpr_b$, $fpr_b$, $tpr_s$, and $fpr_s$, aggregate statistics related to true positive and false positive rates, which are easy to compute from the classifier $h$ using a validation set.\n",
    "\n",
    "This combined vector then passes through the second part of the architecture, which is made up of **fully connected layers** with **ReLU activations**. These layers adjust the quantification embedding using the additional statistics from the classifier to improve the accuracy of the quantification.\n",
    "\n",
    "The final output is a prediction $\\hat{p}_c^{QuaNet}(c|D)$, which represents the probability of class $c$ for the dataset $D$, produced by a **softmax layer**.\n",
    "\n",
    "QuaNet could use quantification predictions from many methods, but it focuses on those that are **computationally efficient** (like CC, ACC, PCC, and PACC). This ensures that the process remains fast while still providing sufficient information for accurate predictions.\n",
    "\n",
    "### Details\n",
    "\n",
    "| Layer | Type | Dimensions | Activation | Dropout |\n",
    "|---|---|---|---|---|\n",
    "| Input | LSTM | 128 | N/A | N/A |\n",
    "| Dense 1 | Dense | 1024 | ReLU | 0.5 |\n",
    "| Dense 2 | Dense | 512 | ReLU | 0.5 |\n",
    "| Output | Dense | 2 | Softmax | N/A |\n",
    "\n",
    "- The LSTM has **64 hidden dimensions**, and since it’s bidirectional, the final LSTM output has **128 dimensions**.\n",
    "- This LSTM output is concatenated with the **8 quantification statistics** (giving a total of 136 dimensions), which is then fed into:\n",
    "  - **Two dense layers** with **1,024** and **512 dimensions**, each using **ReLU activation** and **0.5 dropout**.\n",
    "  - Finally, the output is passed through a **softmax layer** of size 2 to make the final class prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc527bb1-dec8-4f00-b777-f3d407f93165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuaNetModule(\n",
      "  (lstm): LSTM(102, 64, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (ff_layers): ModuleList(\n",
      "    (0): Linear(in_features=136, out_features=1024, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/500 [00:00<?, ?it/s]C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\Lib\\site-packages\\quapy\\method\\_neural.py:233: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  ptrue = torch.as_tensor([sample_data.prevalence()], dtype=torch.float, device=self.device)\n",
      "[QuaNet] epoch=1 [it=499/500]\ttr-mseloss=0.01962 tr-maeloss=0.09637\tval-mseloss=-1.00000 val-maeloss=-1.00000 patience=\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 120.25it/s]\n",
      "[QuaNet] epoch=2 [it=499/500]\ttr-mseloss=0.00497 tr-maeloss=0.05501\tval-mseloss=0.00512 val-maeloss=0.05798 patience=10\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 118.36it/s]\n",
      "[QuaNet] epoch=3 [it=499/500]\ttr-mseloss=0.00496 tr-maeloss=0.05493\tval-mseloss=0.00699 val-maeloss=0.07354 patience=9/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 123.70it/s]\n",
      "[QuaNet] epoch=4 [it=499/500]\ttr-mseloss=0.00436 tr-maeloss=0.05148\tval-mseloss=0.00355 val-maeloss=0.04846 patience=10\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 117.99it/s]\n",
      "[QuaNet] epoch=5 [it=499/500]\ttr-mseloss=0.00498 tr-maeloss=0.05421\tval-mseloss=0.00704 val-maeloss=0.07083 patience=9/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 120.76it/s]\n",
      "[QuaNet] epoch=6 [it=499/500]\ttr-mseloss=0.00402 tr-maeloss=0.04967\tval-mseloss=0.00607 val-maeloss=0.05657 patience=8/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 123.28it/s]\n",
      "[QuaNet] epoch=7 [it=499/500]\ttr-mseloss=0.00612 tr-maeloss=0.06073\tval-mseloss=0.00308 val-maeloss=0.04522 patience=10\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 118.43it/s]\n",
      "[QuaNet] epoch=8 [it=499/500]\ttr-mseloss=0.00502 tr-maeloss=0.05484\tval-mseloss=0.00459 val-maeloss=0.05684 patience=9/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 118.11it/s]\n",
      "[QuaNet] epoch=9 [it=499/500]\ttr-mseloss=0.00455 tr-maeloss=0.05232\tval-mseloss=0.00152 val-maeloss=0.03046 patience=10\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 118.07it/s]\n",
      "[QuaNet] epoch=10 [it=499/500]\ttr-mseloss=0.00431 tr-maeloss=0.05128\tval-mseloss=0.00285 val-maeloss=0.04283 patience=9\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 117.89it/s]\n",
      "[QuaNet] epoch=11 [it=499/500]\ttr-mseloss=0.00371 tr-maeloss=0.04687\tval-mseloss=0.00311 val-maeloss=0.03920 patience=8\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 116.71it/s]\n",
      "[QuaNet] epoch=12 [it=499/500]\ttr-mseloss=0.00395 tr-maeloss=0.04875\tval-mseloss=0.00265 val-maeloss=0.03935 patience=7\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 110.88it/s]\n",
      "[QuaNet] epoch=13 [it=499/500]\ttr-mseloss=0.00409 tr-maeloss=0.05041\tval-mseloss=0.00210 val-maeloss=0.03611 patience=6\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 110.49it/s]\n",
      "[QuaNet] epoch=14 [it=499/500]\ttr-mseloss=0.00431 tr-maeloss=0.05098\tval-mseloss=0.00349 val-maeloss=0.04576 patience=5\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 108.69it/s]\n",
      "[QuaNet] epoch=15 [it=499/500]\ttr-mseloss=0.00435 tr-maeloss=0.05109\tval-mseloss=0.00277 val-maeloss=0.04217 patience=4\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 114.42it/s]\n",
      "[QuaNet] epoch=16 [it=499/500]\ttr-mseloss=0.00336 tr-maeloss=0.04487\tval-mseloss=0.00304 val-maeloss=0.04504 patience=3\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 116.49it/s]\n",
      "[QuaNet] epoch=17 [it=499/500]\ttr-mseloss=0.00375 tr-maeloss=0.04718\tval-mseloss=0.00279 val-maeloss=0.03891 patience=2\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 109.80it/s]\n",
      "[QuaNet] epoch=18 [it=499/500]\ttr-mseloss=0.00342 tr-maeloss=0.04570\tval-mseloss=0.00158 val-maeloss=0.03078 patience=1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 113.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ended by patience exhausted; loading best model parameters in ../checkpoint\\QuaNet-8306-461904-406973-78647-744218 for epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\Lib\\site-packages\\quapy\\method\\_neural.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.quanet.load_state_dict(torch.load(checkpoint))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>QuaNetTrainer(classifier__batch_size=64, classifier__batch_size_test=512,\n",
       "              classifier__device=device(type=&#x27;cpu&#x27;), classifier__drop_p=0.5,\n",
       "              classifier__embedding_size=100, classifier__epochs=200,\n",
       "              classifier__hidden_size=256, classifier__kernel_heights=[3, 5, 7],\n",
       "              classifier__lr=0.001, classifier__padding_length=300,\n",
       "              classifier__patience=10, classifier__repr_size=100,\n",
       "              classifier__stride=1, classifier__weight_decay=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;QuaNetTrainer<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>QuaNetTrainer(classifier__batch_size=64, classifier__batch_size_test=512,\n",
       "              classifier__device=device(type=&#x27;cpu&#x27;), classifier__drop_p=0.5,\n",
       "              classifier__embedding_size=100, classifier__epochs=200,\n",
       "              classifier__hidden_size=256, classifier__kernel_heights=[3, 5, 7],\n",
       "              classifier__lr=0.001, classifier__padding_length=300,\n",
       "              classifier__patience=10, classifier__repr_size=100,\n",
       "              classifier__stride=1, classifier__weight_decay=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "QuaNetTrainer(classifier__batch_size=64, classifier__batch_size_test=512,\n",
       "              classifier__device=device(type='cpu'), classifier__drop_p=0.5,\n",
       "              classifier__embedding_size=100, classifier__epochs=200,\n",
       "              classifier__hidden_size=256, classifier__kernel_heights=[3, 5, 7],\n",
       "              classifier__lr=0.001, classifier__padding_length=300,\n",
       "              classifier__patience=10, classifier__repr_size=100,\n",
       "              classifier__stride=1, classifier__weight_decay=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train QuaNet (alternatively, we can set fit_classifier=True and let QuaNet train the classifier)\n",
    "quantifier = QuaNet(cnn_classifier, qp.environ['SAMPLE_SIZE'], device='cpu')\n",
    "quantifier.fit(abs_dataset.training, fit_classifier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0de8d-011c-4c6f-bd31-62fe0c9da80e",
   "metadata": {},
   "source": [
    "We wrapped `QuaPy`'s error evaluation function and manually modified how each sample is selected; we adjusted the sampling strategy to work with batches where the batch size is equal to the number of sentences that compose each abstract. This allows us to select the entire document based on the filename associated with each sentence. We will also evaluate the results using the standard random sampling technique, where sentences from different abstracts are grouped into the same batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8f9f37-f3ef-42c1-a148-84dffb5558f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on training set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=2)\tByDoc (n=3)\tByDoc (n=4)\tByDoc (n=5)\n",
      "------------\t--------\t-----------\t-----------\t-----------\t-----------\t-----------\n",
      "AE             \t0.0249         \t0.0360         \t0.0320         \t0.0497         \t0.0794         \t0.1111         \n",
      "RAE            \t0.2635         \t0.3390         \t0.3188         \t0.5028         \t0.8205         \t1.1640         \n",
      "MSE            \t0.0006         \t0.0018         \t0.0018         \t0.0043         \t0.0090         \t0.0157         \n",
      "MAE            \t0.0249         \t0.0360         \t0.0320         \t0.0497         \t0.0794         \t0.1111         \n",
      "MRAE           \t0.2635         \t0.3390         \t0.3188         \t0.5028         \t0.8205         \t1.1640         \n",
      "MKLD           \t0.0050         \t0.0325         \t0.0168         \t0.0244         \t0.0418         \t0.0657         \n",
      "\n",
      "Results on test set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=2)\tByDoc (n=3)\tByDoc (n=4)\tByDoc (n=5)\n",
      "------------\t--------\t-----------\t-----------\t-----------\t-----------\t-----------\n",
      "AE             \t0.0876         \t0.0545         \t0.0529         \t0.0544         \t0.0614         \t0.0648         \n",
      "RAE            \t0.9473         \t0.4987         \t0.5144         \t0.5499         \t0.6228         \t0.6827         \n",
      "MSE            \t0.0077         \t0.0055         \t0.0057         \t0.0058         \t0.0086         \t0.0096         \n",
      "MAE            \t0.0876         \t0.0545         \t0.0529         \t0.0544         \t0.0614         \t0.0648         \n",
      "MRAE           \t0.9473         \t0.4987         \t0.5144         \t0.5499         \t0.6228         \t0.6827         \n",
      "MKLD           \t0.0413         \t0.0702         \t0.0577         \t0.0529         \t0.0553         \t0.0562         \n"
     ]
    }
   ],
   "source": [
    "print('Results on training set:')\n",
    "result_train = evaluate(collection=abs_dataset.training, n=[1,2,3,4,5], quantifier=quantifier)\n",
    "\n",
    "print('\\nResults on test set:')\n",
    "result_test = evaluate(collection=abs_dataset.test, n=[1,2,3,4,5], quantifier=quantifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2784f5-4a51-4f26-aad1-ada9a77ba52d",
   "metadata": {},
   "source": [
    "The results seem promising, although the differences observed with the modified sampling strategy are substantial. This observation led us to investigate the effects of increasing the number of elements per batch, which allows us to notice a decrease in error values that tend to align more closely with the standard random sampling technique. This suggests that we might need to explore several solutions:\n",
    "\n",
    "- **Modify the Sampling Strategy During Training**: Adjusting the sampling strategy at training time could help the model learn the distribution of components within a single abstract.\n",
    "  \n",
    "- **Utilize Longer Documents**: We may consider working with longer documents containing more sentences. For instance, the [dataset suggested by Galassi](https://madoc.bib.uni-mannheim.de/46084/1/argmining-18-multi%20%289%29.pdf) contains entire papers annotated with argument components.\n",
    "\n",
    "Let’s observe how the current model behaves with some sample instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d4fcaf7-1cbd-4b79-b6de-ee445d388465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 22310086 - Relations: [0] - Text:\n",
      "\n",
      "\n",
      "To compare the efficacy and safety of tafluprost, a preservative-free (PF) prostaglandin analogue, with PF timolol in patients with open-angle glaucoma or ocular hypertension.\n",
      "Randomized, double-masked, multicenter clinical trial.\n",
      "After discontinuation and washout of existing ocular hypotensive treatment, patients who had intraocular pressure (IOP) =23 and =36 mm Hg in at least 1 eye at the 08:00 hour time point were randomized 1:1 to 12 weeks of treatment with either PF tafluprost 0.0015% or PF timolol 0.5%. IOP was measured 3 times during the day (08:00, 10:00, 16:00 hours) at baseline and at weeks 2, 6, and 12. It was hypothesized that PF tafluprost would be noninferior to PF timolol over 12 weeks with regard to change from baseline IOP. The trial was powered for a noninferiority margin of 1.5 mm Hg at each of the 9 time points assessed.\n",
      "A total of 643 patients were randomized and 618 completed (PF tafluprost = 306, PF timolol = 312). IOPs at the 3 time points assessed during the baseline visit ranged from 23.8 to 26.1 mm Hg in the PF tafluprost group and 23.5 to 26.0 mm Hg in the PF timolol group. IOPs at the 3 time points assessed during the 12-week visit ranged from 17.4 to 18.6 mm Hg for PF tafluprost and 17.9 to 18.5 mm Hg for PF timolol. At all 9 time points, the upper limits of the 2-sided 95% confidence intervals for the difference between treatments in IOP lowering were less than the prespecified noninferiority margin. Similar percentages of PF tafluprost and PF timolol patients reported ocular pain/stinging/irritation (4.4% vs 4.6%) and pruritus (2.5% vs 1.5%). The percentages of PF tafluprost and PF timolol patients reporting conjunctival hyperemia were 4.4% vs 1.2% (nominal P = .016).\n",
      "The IOP-lowering effect of PF tafluprost was noninferior to that of PF timolol. PF tafluprost is an efficacious and generally well-tolerated ocular hypotensive agent.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|█████████████████████████████████████████████████████████████████████| 91/91 [00:00<00:00, 30143.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Relations Labels: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0)\n",
      "\t# Predicted relations labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\t# True distribution relations: [No relation = 0.945054945054945, Relation = 0.054945054945054944]\n",
      "\t# Estimated distribution relations: [No relation = 0.9992772936820984, Relation = 0.0007227116730064154]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|█████████████████████████████████████████████████████████████████████| 91/91 [00:00<00:00, 45492.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Estimated distribution relations on tokenized sentence pairs: [No relation = 0.9992772936820984, Relation = 0.0007227116730064154]\n",
      "\n",
      "\t# AE: 0.0542\n",
      "\t# RAE: 0.4775\n",
      "\t# MSE: 0.0029\n",
      "\t# MAE: 0.0542\n",
      "\t# MRAE: 0.4775\n",
      "\t# MKLD: 0.0842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infer(test_set, indexer, comp_quantifier=None, comp_classifier=None, rel_quantifier=quantifier, rel_classifier=cnn_classifier, filename=None, use_tokenizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a2a35-fee8-4458-98ae-7708ae3f554a",
   "metadata": {},
   "source": [
    "The predictions, although not perfect, appear promising. We compute the posterior estimations in two ways: first, by using sentence tokenization applied to the dataset, taking into account the annotations provided by *Cabrio* and *Villata*; second, by simply applying `sent_tokenize()` to each abstract. The error difference between the two approaches is minimal.\n",
    "\n",
    "### 4. QuaNet with custom training routine\n",
    "\n",
    "Now, let us attempt the first of the previously proposed modifications. We have adjusted the `QuaNet` training routine so that, in each epoch, every batch contains all the sentences from an abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ec734a6-8418-4940-8c3c-7394aa58c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train QuaNet (alternatively, we can set fit_classifier=True and let QuaNet train the classifier)\n",
    "quantifier_custom = QuaNetTrainerABS(cnn_classifier, qp.environ['SAMPLE_SIZE'], device='cpu')\n",
    "quantifier_custom.fit(abs_dataset.training, fit_classifier=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d79122-4774-4458-9bb9-408c4b164847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on training set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=3)\tByDoc (n=5)\tByDoc (n=10)\tByDoc (n=13)\tByDoc (n=15)\n",
      "------------\t--------\t-----------\t-----------\t-----------\t------------\t------------\t------------\n",
      "AE             \t0.1426         \t0.1616         \t0.1423         \t0.1424         \t0.1427         \t0.1430         \t0.1426         \n",
      "RAE            \t0.2651         \t0.3329         \t0.2715         \t0.2679         \t0.2669         \t0.2675         \t0.2661         \n",
      "MSE            \t0.0203         \t0.0381         \t0.0255         \t0.0228         \t0.0217         \t0.0219         \t0.0212         \n",
      "MAE            \t0.1426         \t0.1616         \t0.1423         \t0.1424         \t0.1427         \t0.1430         \t0.1426         \n",
      "MRAE           \t0.2651         \t0.3329         \t0.2715         \t0.2679         \t0.2669         \t0.2675         \t0.2661         \n",
      "MKLD           \t0.0360         \t0.0675         \t0.0450         \t0.0403         \t0.0384         \t0.0386         \t0.0375         \n",
      "\n",
      "Results on test set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=3)\tByDoc (n=5)\tByDoc (n=10)\tByDoc (n=13)\tByDoc (n=15)\n",
      "------------\t--------\t-----------\t-----------\t-----------\t------------\t------------\t------------\n",
      "AE             \t0.1360         \t0.1549         \t0.1362         \t0.1349         \t0.1361         \t0.1352         \t0.1355         \n",
      "RAE            \t0.2526         \t0.3112         \t0.2588         \t0.2541         \t0.2543         \t0.2523         \t0.2532         \n",
      "MSE            \t0.0185         \t0.0341         \t0.0236         \t0.0213         \t0.0199         \t0.0194         \t0.0196         \n",
      "MAE            \t0.1360         \t0.1549         \t0.1362         \t0.1349         \t0.1361         \t0.1352         \t0.1355         \n",
      "MRAE           \t0.2526         \t0.3112         \t0.2588         \t0.2541         \t0.2543         \t0.2523         \t0.2532         \n",
      "MKLD           \t0.0328         \t0.0603         \t0.0417         \t0.0376         \t0.0352         \t0.0343         \t0.0347         \n"
     ]
    }
   ],
   "source": [
    "print('Results on training set:')\n",
    "result_train_custom = evaluate(collection=abs_dataset.training, n=[1,3,5,10, qp.environ['SAMPLE_SIZE'], 15], quantifier=quantifier_custom)\n",
    "\n",
    "print('\\nResults on test set:')\n",
    "result_test_custom = evaluate(collection=abs_dataset.test, n=[1,3,5,10, qp.environ['SAMPLE_SIZE'], 15], quantifier=quantifier_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccbb8325-93d5-4060-8b57-40343ee1d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard QuaNet:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Labels: (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1)\n",
      "\t# Predicted labels: [0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1]\n",
      "\n",
      "\t# True distribution: [Non-components = 0.625, Components = 0.375]\n",
      "\t# Estimated distribution: [Non-components = 0.7147798538208008, Components = 0.28522008657455444]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Estimated distribution on tokenized sentences: [None = 0.7086560130119324, Components = 0.29134401679039]\n",
      "\n",
      "\t# AE: 0.0898\n",
      "\t# RAE: 0.1762\n",
      "\t# MSE: 0.0081\n",
      "\t# MAE: 0.0898\n",
      "\t# MRAE: 0.1762\n",
      "\t# MKLD: 0.0158\n",
      "Custom approach QuaNet:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Labels: (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1)\n",
      "\t# Predicted labels: [0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1]\n",
      "\n",
      "\t# True distribution: [Non-components = 0.625, Components = 0.375]\n",
      "\t# Estimated distribution: [Non-components = 0.37237972021102905, Components = 0.6276203393936157]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Estimated distribution on tokenized sentences: [None = 0.37244391441345215, Components = 0.6275560855865479]\n",
      "\n",
      "\t# AE: 0.2526\n",
      "\t# RAE: 0.4959\n",
      "\t# MSE: 0.0638\n",
      "\t# MAE: 0.2526\n",
      "\t# MRAE: 0.4959\n",
      "\t# MKLD: 0.1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filename = random.choice(test_collection.filenames)\n",
    "\n",
    "print('Standard QuaNet:')\n",
    "infer(test_set, indexer, comp_quantifier=quantifier, comp_classifier=cnn_classifier, rel_quantifier=None, filename=filename, show_text=False, use_tokenizer=True)\n",
    "\n",
    "print('Custom approach QuaNet:')\n",
    "infer(test_set, indexer, comp_quantifier=quantifier_custom, comp_classifier=cnn_classifier, rel_quantifier=None, filename=filename, show_text=False, use_tokenizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd82fb-1046-4ecf-8296-b1bdd1389223",
   "metadata": {},
   "source": [
    "Unfortunately, we observe generally higher error values with this methodology. Moreover, if we run the previous cell multiple times, we notice that the custom quantifier tends to predict an equal distribution of `Components` and `Non-components`: this might reflects the fact that, on average, both the training and test sets have a roughly equal number of argument components and non-components within each individual abstract.\n",
    "\n",
    "```python\n",
    "- Train set:\n",
    "\tLabel 0: 2760 samples\n",
    "\tLabel 1: 2593 samples\n",
    "\n",
    "\tThere are 2 different labels in the train set -> [0, 1]\n",
    "\tAverage number of sentences per file in train set: 13\n",
    "\tMax sentence length: 107\n",
    "\tAverage components per file: 6.48\n",
    "\tAverage non-components per file: 6.90\n",
    "\n",
    "- Test set:\n",
    "\tLabel 0: 1948 samples\n",
    "\tLabel 1: 1880 samples\n",
    "\n",
    "\tThere are 2 different labels in the test set -> [0, 1]\n",
    "\tAverage number of sentences per file in test set: 14\n",
    "\tMax sentence length: 91\n",
    "\tAverage components per file: 6.99\n",
    "\tAverage non-components per file: 7.24\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
