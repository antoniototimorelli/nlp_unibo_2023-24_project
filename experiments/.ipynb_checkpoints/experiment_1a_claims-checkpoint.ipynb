{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b32ce4d-112a-4c2b-814b-7925eee97ce5",
   "metadata": {},
   "source": [
    "# Experiment 1 - Claims Quantification through Sentence-wise Approach\n",
    "\n",
    "This is a variant of the first experiment in which we consider as positive only `Claims` and `MajorClaims`, not `Premises`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee6643c-ae6d-4d48-ad83-18f6eb1638bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Antonio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Antonio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from experiment_1_code import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4b71a-b9f7-4394-ae94-5678e5c8fd67",
   "metadata": {},
   "source": [
    "### 1. Preprocessing\n",
    "Here we preprocess our data by splitting the abstracts into sentences. Each sentence is then labeled as either being a `Claim`, labeled as `1`, or `Not a claim`, labeled as `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471b1a98-8b85-4454-bafe-31ed4ad14d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = read_brat_dataset('../data/train/neoplasm_train', positives=['Claim', 'MajorClaim'])\n",
    "val_set = read_brat_dataset('../data/dev/neoplasm_dev', positives=['Claim', 'MajorClaim'])\n",
    "\n",
    "glaucoma_test = read_brat_dataset('../data/test/glaucoma_test', positives=['Claim', 'MajorClaim'])\n",
    "neoplasm_test = read_brat_dataset('../data/test/neoplasm_test', positives=['Claim', 'MajorClaim'])\n",
    "mixed_test = read_brat_dataset('../data/test/mixed_test', positives=['Claim', 'MajorClaim'])\n",
    "\n",
    "test_set = glaucoma_test + neoplasm_test + mixed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a2cffa-f391-4e11-bbe0-32124242d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train set:\n",
      "\tLabel 0: 3924 samples\n",
      "\tLabel 1: 730 samples\n",
      "\n",
      "\tThere are 2 different labels in the train set -> [0, 1]\n",
      "\tAverage number of sentences per file in train set: 13\n",
      "\tMax sentence length: 107\n",
      "\tAverage components per file: 2.09\n",
      "\tAverage non-components per file: 11.21\n",
      "\n",
      "- Test set:\n",
      "\tLabel 0: 3188 samples\n",
      "\tLabel 1: 650 samples\n",
      "\n",
      "\tThere are 2 different labels in the test set -> [0, 1]\n",
      "\tAverage number of sentences per file in test set: 14\n",
      "\tMax sentence length: 91\n",
      "\tAverage components per file: 2.43\n",
      "\tAverage non-components per file: 11.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_counts_train, avg_sentences_per_file_train = compute_dataset_statistics(train_set, dataset_name=\"train\")\n",
    "label_counts_test, avg_sentences_per_file_test = compute_dataset_statistics(test_set, dataset_name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df97bf69-2965-4927-ac08-b3cdee1b6238",
   "metadata": {},
   "source": [
    "Next, we create the dataset composed by several `FilenameLabelledCollection`, which inherits from `QuaPy`'s `LabelledCollection` class. \n",
    "\n",
    "We created this class since we needed to keep track of the filenames corresponding to each abstract to which the sentences belong. The `index` method is also modified to return `FilenameLabelledCollection` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e4d204-eea2-4378-b97d-06bc31fddfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_collection = FilenameLabelledCollection([data['sentence'] for data in train_set], \n",
    "                                                 [data['label'] for data in train_set], \n",
    "                                                 [data['filename'] for data in train_set])\n",
    "\n",
    "# train_collection, val_collection = train_collection.split_stratified(0.7)\n",
    "# train_collection, val_collection = train_collection.split_stratified_by_filenames(0.75)\n",
    "val_collection = FilenameLabelledCollection([data['sentence'] for data in val_set], \n",
    "                                                 [data['label'] for data in val_set], \n",
    "                                                 [data['filename'] for data in val_set])\n",
    "\n",
    "test_collection = FilenameLabelledCollection([data['sentence'] for data in test_set], \n",
    "                                                 [data['label'] for data in test_set], \n",
    "                                                 [data['filename'] for data in test_set])\n",
    "\n",
    "glaucoma_collection = FilenameLabelledCollection([data['sentence'] for data in glaucoma_test], \n",
    "                                                 [data['label'] for data in glaucoma_test], \n",
    "                                                 [data['filename'] for data in glaucoma_test])\n",
    "\n",
    "neoplasm_collection = FilenameLabelledCollection([data['sentence'] for data in neoplasm_test], \n",
    "                                                 [data['label'] for data in neoplasm_test], \n",
    "                                                 [data['filename'] for data in neoplasm_test])\n",
    "\n",
    "mixed_collection = FilenameLabelledCollection([data['sentence'] for data in mixed_test], \n",
    "                                                 [data['label'] for data in mixed_test], \n",
    "                                                 [data['filename'] for data in mixed_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae1e54e-10bd-40ed-8632-af7263a83863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|███████████████████████████████████████████████| 4654/4654 [00:00<00:00, 74464.85it/s]\n",
      "indexing: 100%|█████████████████████████████████████████████████| 708/708 [00:00<00:00, 45312.00it/s]\n",
      "indexing: 100%|███████████████████████████████████████████████| 3838/3838 [00:00<00:00, 84646.98it/s]\n",
      "indexing: 100%|███████████████████████████████████████████████| 1291/1291 [00:00<00:00, 82809.75it/s]\n",
      "indexing: 100%|███████████████████████████████████████████████| 1338/1338 [00:00<00:00, 85645.07it/s]\n",
      "indexing: 100%|███████████████████████████████████████████████| 1209/1209 [00:00<00:00, 51159.85it/s]\n"
     ]
    }
   ],
   "source": [
    "indexer = qp.data.preprocessing.IndexTransformer(min_df=1)\n",
    "\n",
    "# Create and index the dataset\n",
    "abs_dataset = CustomDataset(training=train_collection, test=test_collection, val=val_collection)\n",
    "index(abs_dataset, indexer, inplace=True)\n",
    "\n",
    "# Index the test collections\n",
    "index(glaucoma_collection, indexer, fit=False, inplace=True)\n",
    "index(neoplasm_collection, indexer, fit=False, inplace=True)\n",
    "index(mixed_collection, indexer, fit=False, inplace=True)\n",
    "\n",
    "qp.environ['SAMPLE_SIZE'] = avg_sentences_per_file_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97b60c-b816-49b5-8b56-8a0a4f499602",
   "metadata": {},
   "source": [
    "### 2. Classifier\n",
    "`QuaNet` requires a classifier that can provide embedded representations of the inputs. In the original paper, `QuaNet` was tested using an `LSTM` as the base classifier; as `QuaPy`'s authors show in their [example](https://hlt-isti.github.io/QuaPy/manuals/methods.html#the-quanet-neural-network), we will use an instantiation of `QuaNet` that employs a `CNN` as a probabilistic classifier, taking its last layer representation as the document embedding.\n",
    "\n",
    "We will use the same set of hyperparameters tuned for the previous model, although tuning on this one could led to better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e338f136-88cd-4033-a53e-c034be38ec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeuralNetwork running on cpu]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNNnet] training epoch=32 tr-loss=0.01027 tr-acc=99.76% tr-macroF1=99.55% patience=1/10 val-loss=0.5C:\\Users\\Antonio\\Documents\\UniBO\\NLP\\project\\nlp_unibo_2023-24_project\\experiments_antonio\\experiment_1_code.py:648: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(self.checkpointpath))\n",
      "[CNNnet] training epoch=32 tr-loss=0.01027 tr-acc=99.76% tr-macroF1=99.55% patience=1/10 val-loss=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ended by patience exhausted; loading best model parameters from ../checkpoints/claims/classifier_net.dat from epoch 22\n",
      "Performing a final training pass over the validation set...\n",
      "[Training complete] - Best loss on validation set: 0.4284893870353699 - Best f1 on validation set: 0.8128353056432426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<experiment_1_code.ScheduledNeuralClassifierTrainer at 0x1a099ab63c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "embedding_size = 180\n",
    "hidden_size = 269   \n",
    "lr = 0.0009964893016712443\n",
    "\n",
    "cnn_module = CNNnet(\n",
    "    abs_dataset.vocabulary_size,\n",
    "    abs_dataset.training.n_classes,\n",
    "    embedding_size=embedding_size,\n",
    "    hidden_size=hidden_size\n",
    ")\n",
    "\n",
    "optimizer = Adam(cnn_module.parameters(), lr=lr)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=2)\n",
    "\n",
    "cnn_classifier = ScheduledNeuralClassifierTrainer(\n",
    "    cnn_module,\n",
    "    lr_scheduler=scheduler,\n",
    "    optim = optimizer,\n",
    "    device='cpu',\n",
    "    checkpointpath='../checkpoints/claims/classifier_net.dat',\n",
    "    padding_length=107,\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "cnn_classifier.fit(*abs_dataset.training.Xy, *abs_dataset.val.Xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "634a48c7-e2df-4b40-a2b5-b38401810af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train set:\n",
      "\tF1: 0.9995935971377502\n",
      "\tAccuracy: 0.9997851310700473\n",
      "- Glaucoma test set:\n",
      "\tF1: 0.763537600192457\n",
      "\tAccuracy: 0.8962044926413633\n",
      "- Neoplasm test set:\n",
      "\tF1: 0.7571175278622087\n",
      "\tAccuracy: 0.8714499252615845\n",
      "- Mixed test set:\n",
      "\tF1: 0.756428775527134\n",
      "\tAccuracy: 0.8734491315136477\n"
     ]
    }
   ],
   "source": [
    "f1_train = 1-qp.error.f1e(abs_dataset.training.labels, cnn_classifier.predict(abs_dataset.training.instances))\n",
    "accuracy_train = 1-qp.error.acce(abs_dataset.training.labels, cnn_classifier.predict(abs_dataset.training.instances))\n",
    "print('- Train set:')\n",
    "print(f'\\tF1: {f1_train}')    \n",
    "print(f'\\tAccuracy: {accuracy_train}')    \n",
    "\n",
    "f1_test_glaucoma = 1-qp.error.f1e(glaucoma_collection.labels, cnn_classifier.predict(glaucoma_collection.instances))\n",
    "accuracy_test_glaucoma = 1-qp.error.acce(glaucoma_collection.labels, cnn_classifier.predict(glaucoma_collection.instances))\n",
    "\n",
    "print('- Glaucoma test set:')\n",
    "print(f'\\tF1: {f1_test_glaucoma}')    \n",
    "print(f'\\tAccuracy: {accuracy_test_glaucoma}')    \n",
    "\n",
    "f1_test_neoplasm = 1-qp.error.f1e(neoplasm_collection.labels, cnn_classifier.predict(neoplasm_collection.instances))\n",
    "accuracy_test_neoplasm = 1-qp.error.acce(neoplasm_collection.labels, cnn_classifier.predict(neoplasm_collection.instances))\n",
    "\n",
    "print('- Neoplasm test set:')\n",
    "print(f'\\tF1: {f1_test_neoplasm}')    \n",
    "print(f'\\tAccuracy: {accuracy_test_neoplasm}')\n",
    "\n",
    "f1_test_mixed = 1-qp.error.f1e(mixed_collection.labels, cnn_classifier.predict(mixed_collection.instances))\n",
    "accuracy_test_mixed = 1-qp.error.acce(mixed_collection.labels, cnn_classifier.predict(mixed_collection.instances))\n",
    "\n",
    "print('- Mixed test set:')\n",
    "print(f'\\tF1: {f1_test_mixed}')    \n",
    "print(f'\\tAccuracy: {accuracy_test_mixed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d1acfd-378b-42cb-b2f1-96fb36477b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 9643663 - Text:\n",
      " To evaluate the efficacy and tolerability of 'Casodex' monotherapy (150 mg daily) for metastatic and locally advanced prostate cancer. A total of 1,453 patients with either confirmed metastatic disease (M1), or T3/T4 non-metastatic disease with elevated prostate-specific antigen (M0) were recruited into one of two identical, multicentre, randomised studies to compare 'Casodex' 150 mg/day with castration. The protocols allowed for combined analysis. At a median follow-up period of approximately 100 weeks for both studies, 'Casodex' 150 mg was found to be less effective than castration in patients with metastatic disease (M1) at entry (hazard ratio of 1.30 for time to death) with a difference in median survival of 6 weeks. In symptomatic M1 patients, 'Casodex' was associated with a statistically significant improvement in subjective response (70%) compared with castration (58%). Analysis of a validated quality-of-life questionnaire proved an advantage for 'Casodex' in sexual interest and physical capacity. 'Casodex' had a substantially lower incidence of hot flushes compared to castration (6-13% compared with 39-44%) and the most commonly reported adverse events were those expected for a potent antiandrogen. However, in patients with M0 disease at entry, the data are still immature with only 13% of M0 patients having died. An initial analysis of this immature data has suggested that the results in these patients may be different to those obtained in patients with M1 disease. A further survival analysis in patients with M0 disease is therefore planned when the data are more mature. 'Casodex' 150 mg is less effective than castration in patients with M1 disease. However, 'Casodex' has shown a benefit in terms of quality of life and subjective response when compared to castration and has an acceptable tolerability profile. Thus 'Casodex' 150 mg monotherapy is an option for patients with M1 prostate cancer for whom surgical or medical castration is not indicated or is not acceptable. \n",
      "\n",
      "\n",
      "**************************************************\n",
      "Component Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tClassification:\n",
      "\t\t# Ground truth components: (0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1)\n",
      "\t\t# Predicted components labels: [0 0 0 0 1 0 0 0 1 0 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infer(test_set, indexer, comp_quantifier=None, comp_classifier=cnn_classifier, rel_quantifier=None, rel_classifier=None, filename=None, use_tokenizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc37da-6239-4833-9c63-03cac51fdb78",
   "metadata": {},
   "source": [
    "### 3. QuaNet \n",
    "The results are solid, let's move onto `QuaNet` training phase. `QuaNet` observes the classification predictions to learn higher-order *quantification embeddings*, which are then refined by incorporating quantification predictions of simple classify-and-count-like methods.\n",
    "\n",
    "![architecture](./images/quanet_architecture.png)\n",
    "\n",
    "The QuaNet architecture (see Figure 1) consists of two main components: a **recurrent component** and a **fully connected component**.\n",
    "\n",
    "#### 3.1 Recurrent Component: Bidirectional LSTM\n",
    "- The core of the model is a **Bidirectional LSTM** (Long Short-Term Memory), a type of recurrent neural network. \n",
    "- The LSTM receives as input a **list of pairs** $⟨Pr(c|x), \\vec{x}⟩$, where:\n",
    "  - $Pr(c|x)$ is the probability that a classifier $h$ assigns class $c$ to document $x$.\n",
    "  - $\\vec{x}$ is the **document embedding**, a vector representing the document's content.\n",
    "- The list is **sorted by the value of $Pr(c|x)$**, meaning the documents are arranged from least to most likely to belong to class $c$.\n",
    "  \n",
    "The **intuition** behind this approach is that the LSTM will \"learn to count\" positive and negative examples. By observing the ordered sequence of probabilities, the LSTM should learn to recognize the point where the documents switch from negative to positive examples. The document embedding $\\vec{x}$ helps the LSTM assign different importance to each document when making its prediction.\n",
    "\n",
    "The output of the LSTM is called a **quantification embedding**—a dense vector representing the information about the quantification task learned from the input data.\n",
    "\n",
    "#### 3.2 Fully Connected Component\n",
    "- The vector returned by the LSTM is combined with additional information, specifically **quantification-related statistics**:\n",
    "  - $\\hat{p}_c^{CC}(D)$, $\\hat{p}_c^{ACC}(D)$, $\\hat{p}_c^{PCC}(D)$, and $\\hat{p}_c^{PACC}(D)$, which are quantification predictions from different methods.\n",
    "  - $tpr_b$, $fpr_b$, $tpr_s$, and $fpr_s$, aggregate statistics related to true positive and false positive rates, which are easy to compute from the classifier $h$ using a validation set.\n",
    "\n",
    "This combined vector then passes through the second part of the architecture, which is made up of **fully connected layers** with **ReLU activations**. These layers adjust the quantification embedding using the additional statistics from the classifier to improve the accuracy of the quantification.\n",
    "\n",
    "The final output is a prediction $\\hat{p}_c^{QuaNet}(c|D)$, which represents the probability of class $c$ for the dataset $D$, produced by a **softmax layer**.\n",
    "\n",
    "QuaNet could use quantification predictions from many methods, but it focuses on those that are **computationally efficient** (like CC, ACC, PCC, and PACC). This ensures that the process remains fast while still providing sufficient information for accurate predictions.\n",
    "\n",
    "### Details\n",
    "\n",
    "| Layer | Type | Dimensions | Activation | Dropout |\n",
    "|---|---|---|---|---|\n",
    "| Input | LSTM | 128 | N/A | N/A |\n",
    "| Dense 1 | Dense | 1024 | ReLU | 0.5 |\n",
    "| Dense 2 | Dense | 512 | ReLU | 0.5 |\n",
    "| Output | Dense | 2 | Softmax | N/A |\n",
    "\n",
    "- The LSTM has **64 hidden dimensions**, and since it’s bidirectional, the final LSTM output has **128 dimensions**.\n",
    "- This LSTM output is concatenated with the **8 quantification statistics** (giving a total of 136 dimensions), which is then fed into:\n",
    "  - **Two dense layers** with **1,024** and **512 dimensions**, each using **ReLU activation** and **0.5 dropout**.\n",
    "  - Finally, the output is passed through a **softmax layer** of size 2 to make the final class prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc527bb1-dec8-4f00-b777-f3d407f93165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuaNetModule(\n",
      "  (lstm): LSTM(102, 64, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (ff_layers): ModuleList(\n",
      "    (0): Linear(in_features=136, out_features=1024, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/500 [00:00<?, ?it/s]C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\Lib\\site-packages\\quapy\\method\\_neural.py:233: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  ptrue = torch.as_tensor([sample_data.prevalence()], dtype=torch.float, device=self.device)\n",
      "[QuaNet] epoch=1 [it=499/500]\ttr-mseloss=0.00481 tr-maeloss=0.03717\tval-mseloss=-1.00000 val-maeloss=\n",
      "100%|█████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 104.56it/s]\n",
      "[QuaNet] epoch=2 [it=499/500]\ttr-mseloss=0.00065 tr-maeloss=0.01784\tval-mseloss=0.00022 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 95.11it/s]\n",
      "[QuaNet] epoch=3 [it=499/500]\ttr-mseloss=0.00037 tr-maeloss=0.01340\tval-mseloss=0.00233 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 88.57it/s]\n",
      "[QuaNet] epoch=4 [it=499/500]\ttr-mseloss=0.00018 tr-maeloss=0.00897\tval-mseloss=0.00040 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 95.10it/s]\n",
      "[QuaNet] epoch=5 [it=499/500]\ttr-mseloss=0.00098 tr-maeloss=0.02128\tval-mseloss=0.00012 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 97.99it/s]\n",
      "[QuaNet] epoch=6 [it=499/500]\ttr-mseloss=0.00028 tr-maeloss=0.00983\tval-mseloss=0.00140 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 88.51it/s]\n",
      "[QuaNet] epoch=7 [it=499/500]\ttr-mseloss=0.00017 tr-maeloss=0.00814\tval-mseloss=0.00004 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 95.18it/s]\n",
      "[QuaNet] epoch=8 [it=499/500]\ttr-mseloss=0.00023 tr-maeloss=0.00930\tval-mseloss=0.00006 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 89.68it/s]\n",
      "[QuaNet] epoch=9 [it=499/500]\ttr-mseloss=0.00026 tr-maeloss=0.00915\tval-mseloss=0.00004 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 92.35it/s]\n",
      "[QuaNet] epoch=10 [it=499/500]\ttr-mseloss=0.00015 tr-maeloss=0.00800\tval-mseloss=0.00007 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 91.04it/s]\n",
      "[QuaNet] epoch=11 [it=499/500]\ttr-mseloss=0.00024 tr-maeloss=0.00892\tval-mseloss=0.00006 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 82.81it/s]\n",
      "[QuaNet] epoch=12 [it=499/500]\ttr-mseloss=0.00016 tr-maeloss=0.00624\tval-mseloss=0.00007 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 89.81it/s]\n",
      "[QuaNet] epoch=13 [it=499/500]\ttr-mseloss=0.00011 tr-maeloss=0.00541\tval-mseloss=0.00001 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 97.98it/s]\n",
      "[QuaNet] epoch=14 [it=499/500]\ttr-mseloss=0.00014 tr-maeloss=0.00626\tval-mseloss=0.00001 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 93.76it/s]\n",
      "[QuaNet] epoch=15 [it=499/500]\ttr-mseloss=0.00016 tr-maeloss=0.00679\tval-mseloss=0.00008 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 95.11it/s]\n",
      "[QuaNet] epoch=16 [it=499/500]\ttr-mseloss=0.00010 tr-maeloss=0.00479\tval-mseloss=0.00013 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 98.08it/s]\n",
      "[QuaNet] epoch=17 [it=499/500]\ttr-mseloss=0.00019 tr-maeloss=0.00725\tval-mseloss=0.00003 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 96.62it/s]\n",
      "[QuaNet] epoch=18 [it=499/500]\ttr-mseloss=0.00010 tr-maeloss=0.00512\tval-mseloss=0.00015 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 92.51it/s]\n",
      "[QuaNet] epoch=19 [it=499/500]\ttr-mseloss=0.00019 tr-maeloss=0.00738\tval-mseloss=0.00009 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 88.54it/s]\n",
      "[QuaNet] epoch=20 [it=499/500]\ttr-mseloss=0.00039 tr-maeloss=0.01090\tval-mseloss=0.00000 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 91.04it/s]\n",
      "[QuaNet] epoch=21 [it=499/500]\ttr-mseloss=0.00011 tr-maeloss=0.00542\tval-mseloss=0.00033 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 93.73it/s]\n",
      "[QuaNet] epoch=22 [it=499/500]\ttr-mseloss=0.00016 tr-maeloss=0.00685\tval-mseloss=0.00000 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 98.03it/s]\n",
      "[QuaNet] epoch=23 [it=499/500]\ttr-mseloss=0.00030 tr-maeloss=0.00908\tval-mseloss=0.00001 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 83.84it/s]\n",
      "[QuaNet] epoch=24 [it=499/500]\ttr-mseloss=0.00018 tr-maeloss=0.00657\tval-mseloss=0.00010 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 93.73it/s]\n",
      "[QuaNet] epoch=25 [it=499/500]\ttr-mseloss=0.00016 tr-maeloss=0.00648\tval-mseloss=0.00022 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 96.58it/s]\n",
      "[QuaNet] epoch=26 [it=499/500]\ttr-mseloss=0.00015 tr-maeloss=0.00553\tval-mseloss=0.00007 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 91.04it/s]\n",
      "[QuaNet] epoch=27 [it=499/500]\ttr-mseloss=0.00008 tr-maeloss=0.00438\tval-mseloss=0.00001 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 91.09it/s]\n",
      "[QuaNet] epoch=28 [it=499/500]\ttr-mseloss=0.00007 tr-maeloss=0.00424\tval-mseloss=0.00001 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 97.98it/s]\n",
      "[QuaNet] epoch=29 [it=499/500]\ttr-mseloss=0.00024 tr-maeloss=0.00730\tval-mseloss=0.00000 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 93.79it/s]\n",
      "[QuaNet] epoch=30 [it=499/500]\ttr-mseloss=0.00018 tr-maeloss=0.00709\tval-mseloss=0.00010 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 89.79it/s]\n",
      "[QuaNet] epoch=31 [it=499/500]\ttr-mseloss=0.00002 tr-maeloss=0.00228\tval-mseloss=0.00007 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 91.07it/s]\n",
      "[QuaNet] epoch=32 [it=499/500]\ttr-mseloss=0.00009 tr-maeloss=0.00372\tval-mseloss=0.00002 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 92.39it/s]\n",
      "[QuaNet] epoch=33 [it=499/500]\ttr-mseloss=0.00020 tr-maeloss=0.00766\tval-mseloss=0.00016 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 96.60it/s]\n",
      "[QuaNet] epoch=34 [it=499/500]\ttr-mseloss=0.00007 tr-maeloss=0.00355\tval-mseloss=0.00002 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 89.72it/s]\n",
      "[QuaNet] epoch=35 [it=499/500]\ttr-mseloss=0.00016 tr-maeloss=0.00631\tval-mseloss=0.00011 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 92.39it/s]\n",
      "[QuaNet] epoch=36 [it=499/500]\ttr-mseloss=0.00011 tr-maeloss=0.00501\tval-mseloss=0.00007 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 95.15it/s]\n",
      "[QuaNet] epoch=37 [it=499/500]\ttr-mseloss=0.00013 tr-maeloss=0.00542\tval-mseloss=0.00000 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 93.36it/s]\n",
      "[QuaNet] epoch=38 [it=499/500]\ttr-mseloss=0.00020 tr-maeloss=0.00717\tval-mseloss=0.00001 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 92.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ended by patience exhausted; loading best model parameters in ../checkpoints/claims\\Quanet-Claims for epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\Lib\\site-packages\\quapy\\method\\_neural.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.quanet.load_state_dict(torch.load(checkpoint))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>QuaNetTrainer(classifier__batch_size=64, classifier__batch_size_test=512,\n",
       "              classifier__device=device(type=&#x27;cpu&#x27;), classifier__drop_p=0.5,\n",
       "              classifier__embedding_size=180, classifier__epochs=200,\n",
       "              classifier__hidden_size=269, classifier__kernel_heights=[3, 5, 7],\n",
       "              classifier__lr=0.001, classifier__padding_length=107,\n",
       "              classifier__patience=10, classifier__repr_size=100,\n",
       "              classifier__stride=1, classifier__weight_decay=0, qdrop_p=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;QuaNetTrainer<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>QuaNetTrainer(classifier__batch_size=64, classifier__batch_size_test=512,\n",
       "              classifier__device=device(type=&#x27;cpu&#x27;), classifier__drop_p=0.5,\n",
       "              classifier__embedding_size=180, classifier__epochs=200,\n",
       "              classifier__hidden_size=269, classifier__kernel_heights=[3, 5, 7],\n",
       "              classifier__lr=0.001, classifier__padding_length=107,\n",
       "              classifier__patience=10, classifier__repr_size=100,\n",
       "              classifier__stride=1, classifier__weight_decay=0, qdrop_p=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "QuaNetTrainer(classifier__batch_size=64, classifier__batch_size_test=512,\n",
       "              classifier__device=device(type='cpu'), classifier__drop_p=0.5,\n",
       "              classifier__embedding_size=180, classifier__epochs=200,\n",
       "              classifier__hidden_size=269, classifier__kernel_heights=[3, 5, 7],\n",
       "              classifier__lr=0.001, classifier__padding_length=107,\n",
       "              classifier__patience=10, classifier__repr_size=100,\n",
       "              classifier__stride=1, classifier__weight_decay=0, qdrop_p=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train QuaNet (alternatively, we can set fit_classifier=True and let QuaNet train the classifier)\n",
    "set_seed(42)\n",
    "\n",
    "quantifier = QuaNet(cnn_classifier, qp.environ['SAMPLE_SIZE'], qdrop_p=0, device='cpu', checkpointdir='../checkpoints/claims', checkpointname='Quanet-Claims')\n",
    "quantifier.fit(abs_dataset.training, fit_classifier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0de8d-011c-4c6f-bd31-62fe0c9da80e",
   "metadata": {},
   "source": [
    "We wrapped `QuaPy`'s error evaluation function and manually modified how each sample is selected; we adjusted the sampling strategy to work with batches where the batch size is equal to the number of sentences that compose each abstract. This allows us to select the entire document based on the filename associated with each sentence. We will also evaluate the results using the standard random sampling technique, where sentences from different abstracts are grouped into the same batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8f9f37-f3ef-42c1-a148-84dffb5558f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=3)\tByDoc (n=5)\tByDoc (n=10)\tByDoc (n=13)\tByDoc (n=15)\n",
      "------------\t--------\t-----------\t-----------\t-----------\t------------\t------------\t------------\n",
      "AE             \t0.0091         \t0.0050         \t0.0113         \t0.0104         \t0.0097         \t0.0096         \t0.0096         \n",
      "RAE            \t0.0284         \t0.0182         \t0.0414         \t0.0360         \t0.0318         \t0.0311         \t0.0310         \n",
      "MSE            \t0.0001         \t0.0001         \t0.0002         \t0.0001         \t0.0001         \t0.0001         \t0.0001         \n",
      "MAE            \t0.0091         \t0.0050         \t0.0113         \t0.0104         \t0.0097         \t0.0096         \t0.0096         \n",
      "MRAE           \t0.0284         \t0.0182         \t0.0414         \t0.0360         \t0.0318         \t0.0311         \t0.0310         \n",
      "MKLD           \t0.0002         \t0.0002         \t0.0007         \t0.0005         \t0.0003         \t0.0003         \t0.0003         \n",
      "- Val set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=3)\tByDoc (n=5)\tByDoc (n=10)\tByDoc (n=13)\tByDoc (n=15)\n",
      "------------\t--------\t-----------\t-----------\t-----------\t------------\t------------\t------------\n",
      "AE             \t0.0066         \t0.0707         \t0.0387         \t0.0248         \t0.0205         \t0.0222         \t0.0228         \n",
      "RAE            \t0.0209         \t0.2376         \t0.1197         \t0.0788         \t0.0627         \t0.0688         \t0.0696         \n",
      "MSE            \t0.0000         \t0.0080         \t0.0026         \t0.0008         \t0.0007         \t0.0006         \t0.0007         \n",
      "MAE            \t0.0066         \t0.0707         \t0.0387         \t0.0248         \t0.0205         \t0.0222         \t0.0228         \n",
      "MRAE           \t0.0209         \t0.2376         \t0.1197         \t0.0788         \t0.0627         \t0.0688         \t0.0696         \n",
      "MKLD           \t0.0001         \t0.0348         \t0.0085         \t0.0023         \t0.0020         \t0.0016         \t0.0019         \n",
      "- Glaucoma test set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=3)\tByDoc (n=5)\tByDoc (n=10)\tByDoc (n=13)\tByDoc (n=15)\n",
      "------------\t--------\t-----------\t-----------\t-----------\t------------\t------------\t------------\n",
      "AE             \t0.0184         \t0.0828         \t0.0480         \t0.0309         \t0.0260         \t0.0276         \t0.0273         \n",
      "RAE            \t0.0599         \t0.2587         \t0.1494         \t0.0959         \t0.0820         \t0.0891         \t0.0876         \n",
      "MSE            \t0.0003         \t0.0108         \t0.0042         \t0.0017         \t0.0009         \t0.0008         \t0.0009         \n",
      "MAE            \t0.0184         \t0.0828         \t0.0480         \t0.0309         \t0.0260         \t0.0276         \t0.0273         \n",
      "MRAE           \t0.0599         \t0.2587         \t0.1494         \t0.0959         \t0.0820         \t0.0891         \t0.0876         \n",
      "MKLD           \t0.0011         \t0.0529         \t0.0182         \t0.0058         \t0.0029         \t0.0027         \t0.0028         \n",
      "- Neoplasm test set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=3)\tByDoc (n=5)\tByDoc (n=10)\tByDoc (n=13)\tByDoc (n=15)\n",
      "------------\t--------\t-----------\t-----------\t-----------\t------------\t------------\t------------\n",
      "AE             \t0.0401         \t0.1008         \t0.0554         \t0.0438         \t0.0399         \t0.0407         \t0.0408         \n",
      "RAE            \t0.1131         \t0.2828         \t0.1479         \t0.1194         \t0.1101         \t0.1139         \t0.1142         \n",
      "MSE            \t0.0016         \t0.0162         \t0.0050         \t0.0028         \t0.0020         \t0.0018         \t0.0019         \n",
      "MAE            \t0.0401         \t0.1008         \t0.0554         \t0.0438         \t0.0399         \t0.0407         \t0.0408         \n",
      "MRAE           \t0.1131         \t0.2828         \t0.1479         \t0.1194         \t0.1101         \t0.1139         \t0.1142         \n",
      "MKLD           \t0.0046         \t0.0674         \t0.0147         \t0.0082         \t0.0059         \t0.0053         \t0.0054         \n",
      "- Mixed test set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=3)\tByDoc (n=5)\tByDoc (n=10)\tByDoc (n=13)\tByDoc (n=15)\n",
      "------------\t--------\t-----------\t-----------\t-----------\t------------\t------------\t------------\n",
      "AE             \t0.0268         \t0.1004         \t0.0546         \t0.0480         \t0.0314         \t0.0354         \t0.0282         \n",
      "RAE            \t0.0781         \t0.2868         \t0.1523         \t0.1441         \t0.0904         \t0.1026         \t0.0802         \n",
      "MSE            \t0.0007         \t0.0166         \t0.0049         \t0.0031         \t0.0015         \t0.0015         \t0.0013         \n",
      "MAE            \t0.0268         \t0.1004         \t0.0546         \t0.0480         \t0.0314         \t0.0354         \t0.0282         \n",
      "MRAE           \t0.0781         \t0.2868         \t0.1523         \t0.1441         \t0.0904         \t0.1026         \t0.0802         \n",
      "MKLD           \t0.0021         \t0.0686         \t0.0180         \t0.0100         \t0.0045         \t0.0045         \t0.0037         \n"
     ]
    }
   ],
   "source": [
    "print('- Train set:')\n",
    "result_train = evaluate(collection=abs_dataset.training, n=[1,3,5,10, qp.environ['SAMPLE_SIZE'], 15], quantifier=quantifier)\n",
    "\n",
    "print('- Val set:')\n",
    "result_train = evaluate(collection=abs_dataset.val, n=[1,3,5,10, qp.environ['SAMPLE_SIZE'], 15], quantifier=quantifier)\n",
    "\n",
    "print('- Glaucoma test set:')\n",
    "result_test = evaluate(collection=glaucoma_collection, n=[1,3,5,10, qp.environ['SAMPLE_SIZE'], 15], quantifier=quantifier)\n",
    "\n",
    "print('- Neoplasm test set:')\n",
    "result_test = evaluate(collection=neoplasm_collection, n=[1,3,5,10, qp.environ['SAMPLE_SIZE'], 15], quantifier=quantifier)\n",
    "\n",
    "print('- Mixed test set:')\n",
    "result_test = evaluate(collection=mixed_collection, n=[1,3,5,10, qp.environ['SAMPLE_SIZE'], 15], quantifier=quantifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2784f5-4a51-4f26-aad1-ada9a77ba52d",
   "metadata": {},
   "source": [
    "The results seem promising, although the differences observed with the modified sampling strategy are substantial. This observation led us to investigate the effects of increasing the number of elements per batch, which allows us to notice a decrease in error values that tend to align more closely with the standard random sampling technique. This suggests that we might need to explore several solutions:\n",
    "\n",
    "- **Modify the Sampling Strategy During Training**: Adjusting the sampling strategy at training time could help the model learn the distribution of components within a single abstract.\n",
    "  \n",
    "- **Utilize Longer Documents**: We may consider working with longer documents containing more sentences. For instance, the [dataset suggested by Galassi](https://madoc.bib.uni-mannheim.de/46084/1/argmining-18-multi%20%289%29.pdf) contains entire papers annotated with argument components.\n",
    "\n",
    "Let’s observe how the current model behaves with some sample instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d4fcaf7-1cbd-4b79-b6de-ee445d388465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 9643663 - Text:\n",
      " To evaluate the efficacy and tolerability of 'Casodex' monotherapy (150 mg daily) for metastatic and locally advanced prostate cancer. A total of 1,453 patients with either confirmed metastatic disease (M1), or T3/T4 non-metastatic disease with elevated prostate-specific antigen (M0) were recruited into one of two identical, multicentre, randomised studies to compare 'Casodex' 150 mg/day with castration. The protocols allowed for combined analysis. At a median follow-up period of approximately 100 weeks for both studies, 'Casodex' 150 mg was found to be less effective than castration in patients with metastatic disease (M1) at entry (hazard ratio of 1.30 for time to death) with a difference in median survival of 6 weeks. In symptomatic M1 patients, 'Casodex' was associated with a statistically significant improvement in subjective response (70%) compared with castration (58%). Analysis of a validated quality-of-life questionnaire proved an advantage for 'Casodex' in sexual interest and physical capacity. 'Casodex' had a substantially lower incidence of hot flushes compared to castration (6-13% compared with 39-44%) and the most commonly reported adverse events were those expected for a potent antiandrogen. However, in patients with M0 disease at entry, the data are still immature with only 13% of M0 patients having died. An initial analysis of this immature data has suggested that the results in these patients may be different to those obtained in patients with M1 disease. A further survival analysis in patients with M0 disease is therefore planned when the data are more mature. 'Casodex' 150 mg is less effective than castration in patients with M1 disease. However, 'Casodex' has shown a benefit in terms of quality of life and subjective response when compared to castration and has an acceptable tolerability profile. Thus 'Casodex' 150 mg monotherapy is an option for patients with M1 prostate cancer for whom surgical or medical castration is not indicated or is not acceptable. \n",
      "\n",
      "\n",
      "**************************************************\n",
      "Component Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tQuantification:\n",
      "\t\t# True distribution components: [Class 0 = 0.6154, Class 1 = 0.3846]\n",
      "\t\t# Estimated distribution components: [Class 0 = 0.6111, Class 1 = 0.3889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|██████████████████████████████████████████████████████████████| 13/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Estimated distribution on tokenized components: [Class 0 = 0.6111, Class 1 = 0.3889]\n",
      "\n",
      "\t# AE: 0.0042\n",
      "\t# RAE: 0.0083\n",
      "\t# MSE: 0.0000\n",
      "\t# MAE: 0.0042\n",
      "\t# MRAE: 0.0083\n",
      "\t# MKLD: 0.0000\n",
      "\tClassification:\n",
      "\t\t# Ground truth components: (0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1)\n",
      "\t\t# Predicted components labels: [0 0 0 0 1 0 0 0 1 0 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infer(test_set, indexer, comp_quantifier=quantifier, comp_classifier=cnn_classifier, filename=None, use_tokenizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a2a35-fee8-4458-98ae-7708ae3f554a",
   "metadata": {},
   "source": [
    "The predictions, although not perfect, appear promising. We compute the posterior estimations in two ways: first, by using sentence tokenization applied to the dataset, taking into account the annotations provided by *Cabrio* and *Villata*; second, by simply applying `sent_tokenize()` to each abstract. The error difference between the two approaches is minimal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
