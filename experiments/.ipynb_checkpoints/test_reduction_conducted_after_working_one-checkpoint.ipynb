{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b32ce4d-112a-4c2b-814b-7925eee97ce5",
   "metadata": {},
   "source": [
    "# Experiment 4 - Relations\n",
    "Now that we have our model capable of detecting components, let us consider as label the number of relation: we still split each abstract into sentences and label, make each possible combination between them and label each combined sentence as either *No related* or *Related*, corresponding to 0 and 1 respectively.\n",
    "\n",
    "During inference, we will use the same sampling technique that processes all the sentences that form an abstract. This time, our goal is to determine the percentage of relations between arguments' components that each abstract contains, and inspect if this information along with the percentage of components could help to build a working model that predicts the number of arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee6643c-ae6d-4d48-ad83-18f6eb1638bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Antonio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from experiment_4_code import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4b71a-b9f7-4394-ae94-5678e5c8fd67",
   "metadata": {},
   "source": [
    "### 1. Preprocessing\n",
    "Here we preprocess our data by splitting the abstracts into sentences. Each combination of two sentences is then labeled as either being a `Relationship`, labeled as `1`, or `Not relationship`, labeled as `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "69730ea9-fd1f-463b-b2bc-99febded91d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_boundaries(text, components_boundaries, components_types):\n",
    "    \"\"\"\n",
    "    Split the text into parts based on the component boundaries and label them accordingly.\n",
    "    \n",
    "    This returns a list of tuples: (text_part, label, arg_id), where:\n",
    "        - label is: 0 -> None, 1 -> Claim, 2 -> Premise\n",
    "        - arg_id is the component ID (e.g., T1, T2) if it's a Claim or Premise, otherwise None\n",
    "    \"\"\"\n",
    "    labeled_parts = []\n",
    "    last_pos = 0\n",
    "\n",
    "    # Iterate over sorted boundaries and extract the corresponding text parts\n",
    "    sorted_boundaries = sorted([(start, end, components_types[key], key) \n",
    "                                for key, bounds in components_boundaries.items() \n",
    "                                for start, end in bounds])\n",
    "\n",
    "    for start, end, label_type, arg_id in sorted_boundaries:\n",
    "        # Add the non-labeled part between the previous boundary and the current one\n",
    "        if last_pos < start:\n",
    "            non_labeled_part = text[last_pos:start]\n",
    "            if non_labeled_part.strip():  # Avoid empty parts\n",
    "                labeled_parts.append((non_labeled_part, 0, None))\n",
    "\n",
    "        # Add the labeled part (Claim or Premise) with its component ID (arg_id)\n",
    "        labeled_parts.append((text[start:end], 1 if label_type in ['Claim', 'MajorClaim', 'Premise'] else 0, arg_id))\n",
    "        \n",
    "        last_pos = end\n",
    "\n",
    "    # Add the remaining part of the text (after the last component)\n",
    "    if last_pos < len(text):\n",
    "        remaining_part = text[last_pos:]\n",
    "        if remaining_part.strip():\n",
    "            labeled_parts.append((remaining_part, 0, None))\n",
    "\n",
    "    return labeled_parts\n",
    "\n",
    "def label_sentences(text, reduce, components_boundaries, components_types):\n",
    "    \"\"\"\n",
    "    First split the text according to the component boundaries, label premises and claims,\n",
    "    and then split the remaining parts into sentences and label them as None.\n",
    "    \"\"\"\n",
    "    labeled_sentences = []\n",
    "    \n",
    "    # Split text based on boundaries and label Claims/Premises\n",
    "    labeled_parts = split_by_boundaries(text, components_boundaries, components_types)\n",
    "    \n",
    "    # Now process each part\n",
    "    for part, label, arg_id in labeled_parts:\n",
    "        if label == 0:\n",
    "            # For the non-labeled parts, split into sentences\n",
    "            sentences = sent_tokenize(part)\n",
    "            for sentence in sentences:\n",
    "                labeled_sentences.append({'sentence': sentence, 'label': 0, 'arg_id': None})\n",
    "        else:\n",
    "            # For labeled parts (Claim or Premise), treat the entire part as one sentence\n",
    "            labeled_sentences.append({'sentence': part, 'label': label, 'arg_id': arg_id})\n",
    "\n",
    "    return labeled_sentences\n",
    "\n",
    "def read_brat_dataset(folder, reduce=False):\n",
    "    dataset, temp_sentence, merge = [], \"\", False\n",
    "    \n",
    "    for root, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            positives,negatives = 0,0\n",
    "            if file.endswith('.ann'):\n",
    "                ann_path = os.path.join(root, file)\n",
    "                txt_path = ann_path.replace('.ann', '.txt')\n",
    "                \n",
    "                if os.path.exists(txt_path):\n",
    "                    with open(ann_path, 'r', encoding='utf-8') as ann_f, open(txt_path, 'r', encoding='utf-8') as txt_f:\n",
    "                        annotations = [line.strip().split('\\t') for line in ann_f]\n",
    "                        text = txt_f.read()\n",
    "\n",
    "                        # Extract component boundaries and types\n",
    "                        components_boundaries = {\n",
    "                            ann[0]: [(int(ann[1].split(' ')[1]), int(ann[1].split(' ')[2]))] \n",
    "                            for ann in annotations if ann[0].startswith('T')\n",
    "                        }\n",
    "                        components_types = {\n",
    "                            ann[0]: ann[1].split(' ')[0] \n",
    "                            for ann in annotations if ann[0].startswith('T')\n",
    "                        }\n",
    "\n",
    "                        # Extract relations between components (using Arg1 and Arg2)\n",
    "                        relations = {}\n",
    "                        for ann in annotations:\n",
    "                            if ann[0].startswith('R'):\n",
    "                                relation_type, arg1, arg2 = ann[1].split(' ')\n",
    "                                arg1_id = arg1.split(':')[1]\n",
    "                                arg2_id = arg2.split(':')[1]\n",
    "                                relations[(arg1_id, arg2_id)] = relation_type\n",
    "                                \n",
    "                        # Label sentences based on boundaries first, then split the remaining text into sentences\n",
    "                        labeled_sentences = label_sentences(text, reduce, components_boundaries, components_types)\n",
    "                        \n",
    "                        # Store sentence combinations and assign relation labels\n",
    "                        sentence_combinations = list(combinations(labeled_sentences, 2))\n",
    "                        for sentence1, sentence2 in sentence_combinations:\n",
    "                            label = 0  # Default label is 0 (no relation)\n",
    "                            rel_components = None\n",
    "                            if sentence1['arg_id'] and sentence2['arg_id']:\n",
    "                                # Check if there is a relation between the component IDs of the two sentences\n",
    "                                if (sentence1['arg_id'], sentence2['arg_id']) in relations:\n",
    "                                    label = 1  # Label 1 if relation exists between the components\n",
    "                                    rel_components = (sentence1['arg_id'], sentence2['arg_id'])\n",
    "                                elif (sentence2['arg_id'], sentence1['arg_id']) in relations:\n",
    "                                    label = 1  # Label 1 if relation exists between the components\n",
    "                                    rel_components = (sentence2['arg_id'], sentence1['arg_id'])\n",
    "\n",
    "                                if label:\n",
    "                                    positives+=1\n",
    "                                    dataset.append({\n",
    "                                        'text': text,\n",
    "                                        'filename': file.split('.')[0],\n",
    "                                        'components': rel_components, \n",
    "                                        'sentence_pair': sentence1['sentence'] + sentence2['sentence'],\n",
    "                                        'label': label  \n",
    "                                    })\n",
    "                                else:\n",
    "                                    negatives+=1\n",
    "                                    if negatives <= positives + 4 and reduce:\n",
    "                                        dataset.append({\n",
    "                                            'text': text,\n",
    "                                            'filename': file.split('.')[0],\n",
    "                                            'components': rel_components, \n",
    "                                            'sentence_pair': sentence1['sentence'] + sentence2['sentence'],\n",
    "                                            'label': label  \n",
    "                                        })\n",
    "                                    elif not reduce:\n",
    "                                        dataset.append({\n",
    "                                            'text': text,\n",
    "                                            'filename': file.split('.')[0],\n",
    "                                            'components': rel_components, \n",
    "                                            'sentence_pair': sentence1['sentence'] + sentence2['sentence'],\n",
    "                                            'label': label  \n",
    "                                        })\n",
    "                            elif sentence1['arg_id'] or sentence2['arg_id']:\n",
    "                                dataset.append({\n",
    "                                    'text': text,\n",
    "                                    'filename': file.split('.')[0],\n",
    "                                    'components': rel_components, \n",
    "                                    'sentence_pair': sentence1['sentence'] + sentence2['sentence'],\n",
    "                                    'label': 0  \n",
    "                                })\n",
    "                                    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "471b1a98-8b85-4454-bafe-31ed4ad14d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = read_brat_dataset('../data/train/neoplasm_train') + read_brat_dataset('../data/dev/neoplasm_dev')\n",
    "test_set = read_brat_dataset('../data/test/glaucoma_test') + read_brat_dataset('../data/test/neoplasm_test') + read_brat_dataset('../data/test/mixed_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f6a2cffa-f391-4e11-bbe0-32124242d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train set:\n",
      "\tLabel 0: 24969 samples\n",
      "\tLabel 1: 1636 samples\n",
      "\n",
      "\tThere are 2 different labels in the train set -> [0, 1]\n",
      "\tAverage number of sentences pairs per file in train set: 67\n",
      "\tMax sentence pair length: 162\n",
      "\tAverage relationships per file: 4.16\n",
      "\tAverage no relationships per file: 62.42\n",
      "\n",
      "- Test set:\n",
      "\tLabel 0: 17528 samples\n",
      "\tLabel 1: 1120 samples\n",
      "\n",
      "\tThere are 2 different labels in the test set -> [0, 1]\n",
      "\tAverage number of sentences pairs per file in test set: 69\n",
      "\tMax sentence pair length: 140\n",
      "\tAverage relationships per file: 4.23\n",
      "\tAverage no relationships per file: 65.16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_counts_train, avg_sentences_per_file_train = compute_dataset_statistics(train_set, dataset_name=\"train\")\n",
    "label_counts_test, avg_sentences_per_file_test = compute_dataset_statistics(test_set, dataset_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "82f3ed6f-ab29-453d-b0f1-92bc36d128e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce = True\n",
    "train_set_reduced = read_brat_dataset('../data/train/neoplasm_train', reduce) + read_brat_dataset('../data/dev/neoplasm_dev', reduce)\n",
    "test_set_reduced = read_brat_dataset('../data/test/glaucoma_test', reduce) + read_brat_dataset('../data/test/neoplasm_test', reduce) + read_brat_dataset('../data/test/mixed_test', reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ff69f93e-f7a0-4f7f-9ffc-d36c223f3ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train set:\n",
      "\tLabel 0: 20184 samples\n",
      "\tLabel 1: 1636 samples\n",
      "\n",
      "\tThere are 2 different labels in the train set -> [0, 1]\n",
      "\tAverage number of sentences pairs per file in train set: 55\n",
      "\tMax sentence pair length: 162\n",
      "\tAverage relationships per file: 4.16\n",
      "\tAverage no relationships per file: 50.46\n",
      "\n",
      "- Test set:\n",
      "\tLabel 0: 14484 samples\n",
      "\tLabel 1: 1120 samples\n",
      "\n",
      "\tThere are 2 different labels in the test set -> [0, 1]\n",
      "\tAverage number of sentences pairs per file in test set: 58\n",
      "\tMax sentence pair length: 140\n",
      "\tAverage relationships per file: 4.23\n",
      "\tAverage no relationships per file: 53.84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_counts_train_reduced, avg_sentences_per_file_train_reduced = compute_dataset_statistics(train_set_reduced, dataset_name=\"train\")\n",
    "label_counts_test_reduced, avg_sentences_per_file_test_reduced = compute_dataset_statistics(test_set_reduced, dataset_name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b11b11-4c24-4a19-8721-f132b39f4705",
   "metadata": {},
   "source": [
    "Follows an example of what our dictionary looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fb562ae9-ef26-4bce-bd30-d7c8e7fb543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_file_info(train_set, filename='16416368') \n",
    "# display_file_info(train_set, filename=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df97bf69-2965-4927-ac08-b3cdee1b6238",
   "metadata": {},
   "source": [
    "Next, we create the dataset `FilenameLabelledCollection`, which inherits from `QuaPy`'s `LabelledCollection` class. This allows us to keep track of the filenames corresponding to each abstract to which the sentences belong. The `index` method is also modified to return two `FilenameLabelledCollection` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "14e4d204-eea2-4378-b97d-06bc31fddfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_collection = FilenameLabelledCollection([data['sentence_pair'] for data in train_set], \n",
    "                                                 [data['label'] for data in train_set], \n",
    "                                                 [data['filename'] for data in train_set], \n",
    "                                                 classes=list(label_counts_train.keys()))\n",
    "\n",
    "test_collection = FilenameLabelledCollection([data['sentence_pair'] for data in test_set], \n",
    "                                                 [data['label'] for data in test_set], \n",
    "                                                 [data['filename'] for data in test_set], \n",
    "                                                 classes=list(label_counts_test.keys()))\n",
    "\n",
    "train_collection_reduced = FilenameLabelledCollection([data['sentence_pair'] for data in train_set_reduced], \n",
    "                                                 [data['label'] for data in train_set_reduced], \n",
    "                                                 [data['filename'] for data in train_set_reduced], \n",
    "                                                 classes=list(label_counts_train_reduced.keys()))\n",
    "\n",
    "test_collection_reduced = FilenameLabelledCollection([data['sentence_pair'] for data in test_set_reduced], \n",
    "                                                 [data['label'] for data in test_set_reduced], \n",
    "                                                 [data['filename'] for data in test_set_reduced], \n",
    "                                                 classes=list(label_counts_test_reduced.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3ae1e54e-10bd-40ed-8632-af7263a83863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|███████████████████████████████████████████████| 8158/8158 [00:00<00:00, 47694.50it/s]\n",
      "indexing: 100%|███████████████████████████████████████████████| 5522/5522 [00:00<00:00, 46554.57it/s]\n",
      "indexing: 100%|███████████████████████████████████████████████| 3373/3373 [00:00<00:00, 44832.35it/s]\n",
      "indexing: 100%|███████████████████████████████████████████████| 2478/2478 [00:00<00:00, 43837.54it/s]\n"
     ]
    }
   ],
   "source": [
    "def index(dataset: Dataset, indexer, inplace=False, fit=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Indexes the tokens of a textual :class:`quapy.data.base.Dataset` of string documents.\n",
    "    To index a document means to replace each different token by a unique numerical index.\n",
    "    Rare words (i.e., words occurring less than `min_df` times) are replaced by a special token `UNK`\n",
    "\n",
    "    :param dataset: a :class:`quapy.data.base.Dataset` object where the instances of training and test documents\n",
    "        are lists of str\n",
    "    :param min_df: minimum number of occurrences below which the term is replaced by a `UNK` index\n",
    "    :param inplace: whether or not to apply the transformation inplace (True), or to a new copy (False, default)\n",
    "    :param kwargs: the rest of parameters of the transformation (as for sklearn's\n",
    "        `CountVectorizer <https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html>_`)\n",
    "    :return: a new :class:`quapy.data.base.Dataset` (if inplace=False) or a reference to the current\n",
    "        :class:`quapy.data.base.Dataset` (inplace=True) consisting of lists of integer values representing indices.\n",
    "    \"\"\"\n",
    "    qp.data.preprocessing.__check_type(dataset.training.instances, np.ndarray, str)\n",
    "    qp.data.preprocessing.__check_type(dataset.test.instances, np.ndarray, str)\n",
    "\n",
    "    training_index = indexer.fit_transform(dataset.training.instances) if fit else indexer.transform(dataset.training.instances) \n",
    "    test_index = indexer.transform(dataset.test.instances)\n",
    "\n",
    "    training_index = np.asarray(training_index, dtype=object)\n",
    "    test_index = np.asarray(test_index, dtype=object)\n",
    "\n",
    "    if inplace:\n",
    "        dataset.training = FilenameLabelledCollection(training_index, dataset.training.labels, dataset.training.filenames, dataset.classes_)\n",
    "        dataset.test = FilenameLabelledCollection(test_index, dataset.test.labels, dataset.test.filenames, dataset.classes_)\n",
    "        dataset.vocabulary = indexer.vocabulary_\n",
    "        return dataset\n",
    "    else:\n",
    "        training = FilenameLabelledCollection(training_index, dataset.training.labels.copy(), dataset.training.filenames, dataset.classes_)\n",
    "        test = FilenameLabelledCollection(test_index, dataset.test.labels.copy(), dataset.test.filenames, dataset.classes_)\n",
    "        return Dataset(training, test, indexer.vocabulary_)\n",
    "        \n",
    "indexer = qp.data.preprocessing.IndexTransformer(min_df=1)\n",
    "\n",
    "abs_dataset = Dataset(train_collection, test_collection)\n",
    "index(abs_dataset, indexer, inplace=True)\n",
    "\n",
    "abs_dataset_reduced = Dataset(train_collection_reduced, test_collection_reduced)\n",
    "index(abs_dataset_reduced, indexer, fit=False, inplace=True)\n",
    "\n",
    "qp.environ['SAMPLE_SIZE'] = avg_sentences_per_file_train\n",
    "# qp.environ['SAMPLE_SIZE'] = avg_sentences_per_file_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97b60c-b816-49b5-8b56-8a0a4f499602",
   "metadata": {},
   "source": [
    "### 2. Classifier\n",
    "`QuaNet` requires a classifier that can provide embedded representations of the inputs. In the original paper, `QuaNet` was tested using an `LSTM` as the base classifier; as `QuaPy`'s authors show in their [example](https://hlt-isti.github.io/QuaPy/manuals/methods.html#the-quanet-neural-network), we will use an instantiation of `QuaNet` that employs a `CNN` as a probabilistic classifier, taking its last layer representation as the document embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30c84307-4146-48f2-9274-c763d1ce0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "class WeightedNeuralClassifierTrainer(NeuralClassifierTrainer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 net: 'TextClassifierNet',\n",
    "                 lr=1e-3,\n",
    "                 weight_decay=0,\n",
    "                 patience=10,\n",
    "                 epochs=200,\n",
    "                 batch_size=64,\n",
    "                 batch_size_test=512,\n",
    "                 padding_length=300,\n",
    "                 device='cuda',\n",
    "                 checkpointpath='../checkpoint/classifier_net.dat',\n",
    "                 criterion=torch.nn.CrossEntropyLoss()):\n",
    "\n",
    "        super().__init__(\n",
    "                 net,\n",
    "                 lr=lr,\n",
    "                 weight_decay=weight_decay,\n",
    "                 patience=patience,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=batch_size,\n",
    "                 batch_size_test=batch_size_test,\n",
    "                 padding_length=padding_length,\n",
    "                 device=device,\n",
    "                 checkpointpath=checkpointpath)\n",
    "        \n",
    "        self.criterion = criterion\n",
    "    \n",
    "    def _train_epoch(self, data, status, pbar, epoch):\n",
    "        self.net.train()\n",
    "        losses, predictions, true_labels = [], [], []\n",
    "        for xi, yi in data:\n",
    "            self.optim.zero_grad()\n",
    "            logits = self.net.forward(xi)\n",
    "            loss = self.criterion(logits, yi)\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            losses.append(loss.item())\n",
    "            preds = torch.softmax(logits, dim=-1).detach().cpu().numpy().argmax(axis=-1)\n",
    "\n",
    "            status[\"loss\"] = np.mean(losses)\n",
    "            predictions.extend(preds.tolist())\n",
    "            true_labels.extend(yi.detach().cpu().numpy().tolist())\n",
    "            status[\"acc\"] = accuracy_score(true_labels, predictions)\n",
    "            status[\"f1\"] = f1_score(true_labels, predictions, average='macro')\n",
    "            self.__update_progress_bar(pbar, epoch)\n",
    "\n",
    "    def _test_epoch(self, data, status, pbar, epoch):\n",
    "        self.net.eval()\n",
    "        losses, predictions, true_labels = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for xi, yi in data:\n",
    "                logits = self.net.forward(xi)\n",
    "                loss = self.criterion(logits, yi)\n",
    "                losses.append(loss.item())\n",
    "                preds = torch.softmax(logits, dim=-1).detach().cpu().numpy().argmax(axis=-1)\n",
    "                predictions.extend(preds.tolist())\n",
    "                true_labels.extend(yi.detach().cpu().numpy().tolist())\n",
    "\n",
    "            status[\"loss\"] = np.mean(losses)\n",
    "            status[\"acc\"] = accuracy_score(true_labels, predictions)\n",
    "            status[\"f1\"] = f1_score(true_labels, predictions, average='macro')\n",
    "            self.__update_progress_bar(pbar, epoch)\n",
    "\n",
    "    def __update_progress_bar(self, pbar, epoch):\n",
    "        pbar.set_description(f'[{self.net.__class__.__name__}] training epoch={epoch} '\n",
    "                             f'tr-loss={self.status[\"tr\"][\"loss\"]:.5f} '\n",
    "                             f'tr-acc={100 * self.status[\"tr\"][\"acc\"]:.2f}% '\n",
    "                             f'tr-macroF1={100 * self.status[\"tr\"][\"f1\"]:.2f}% '\n",
    "                             f'patience={self.early_stop.patience}/{self.early_stop.PATIENCE_LIMIT} '\n",
    "                             f'val-loss={self.status[\"va\"][\"loss\"]:.5f} '\n",
    "                             f'val-acc={100 * self.status[\"va\"][\"acc\"]:.2f}% '\n",
    "                             f'macroF1={100 * self.status[\"va\"][\"f1\"]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb9680a2-8b2f-41e7-8fd3-139ee4e96e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeuralNetwork running on cpu]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNNnet] training epoch=14 tr-loss=0.02162 tr-acc=99.15% tr-macroF1=99.15% patience=1/10 val-loss=1.4C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\Lib\\site-packages\\quapy\\classification\\neural.py:203: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(checkpoint))\n",
      "[CNNnet] training epoch=14 tr-loss=0.02162 tr-acc=99.15% tr-macroF1=99.15% patience=1/10 val-loss=1.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ended by patience exhasted; loading best model parameters in ../checkpoint/classifier_net.dat for epoch 4\n",
      "performing one training pass over the validation set...\n",
      "[done]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<quapy.classification.neural.NeuralClassifierTrainer at 0x135ea618650>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cnn_module = CNNnet(abs_dataset.vocabulary_size, abs_dataset.training.n_classes)\n",
    "\n",
    "# negative_samples = len([el for el in abs_dataset_reduced.training.labels if el == 0])\n",
    "# positive_samples = len([el for el in abs_dataset_reduced.training.labels if el == 1])\n",
    "# class_weights = torch.tensor([1-(negative_samples/(negative_samples+positive_samples)),1-(positive_samples/(negative_samples+positive_samples))] )\n",
    "# criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# cnn_classifier = WeightedNeuralClassifierTrainer(cnn_module, device='cpu', criterion=criterion)\n",
    "# cnn_classifier.fit(*abs_dataset_reduced.training.Xy)\n",
    "\n",
    "cnn_module = CNNnet(abs_dataset.vocabulary_size, abs_dataset.training.n_classes)\n",
    "cnn_classifier = NeuralClassifierTrainer(cnn_module, device='cpu')\n",
    "cnn_classifier.fit(*abs_dataset_reduced.training.Xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "634a48c7-e2df-4b40-a2b5-b38401810af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train set:\n",
      "\tF1: 0.6595181368937398\n",
      "\tAccuracy: 0.6978426084824711\n",
      "- Test set:\n",
      "\tF1: 0.5787563314172924\n",
      "\tAccuracy: 0.6481347337921043\n"
     ]
    }
   ],
   "source": [
    "# f1_train = 1-qp.error.f1e(abs_dataset_reduced.training.labels, cnn_classifier.predict(abs_dataset_reduced.training.instances))\n",
    "# accuracy_train = 1-qp.error.acce(abs_dataset_reduced.training.labels, cnn_classifier.predict(abs_dataset_reduced.training.instances))\n",
    "# print('- Train set:')\n",
    "# print(f'\\tF1: {f1_train}')    \n",
    "# print(f'\\tAccuracy: {accuracy_train}')    \n",
    "\n",
    "# f1_test = 1-qp.error.f1e(abs_dataset_reduced.test.labels, cnn_classifier.predict(abs_dataset_reduced.test.instances))\n",
    "# accuracy_test = 1-qp.error.acce(abs_dataset_reduced.test.labels, cnn_classifier.predict(abs_dataset_reduced.test.instances))\n",
    "# print('- Test set:')\n",
    "# print(f'\\tF1: {f1_test}')    \n",
    "# print(f'\\tAccuracy: {accuracy_test}')    \n",
    "\n",
    "f1_train = 1-qp.error.f1e(abs_dataset.training.labels, cnn_classifier.predict(abs_dataset.training.instances))\n",
    "accuracy_train = 1-qp.error.acce(abs_dataset.training.labels, cnn_classifier.predict(abs_dataset.training.instances))\n",
    "print('- Train set:')\n",
    "print(f'\\tF1: {f1_train}')    \n",
    "print(f'\\tAccuracy: {accuracy_train}')    \n",
    "\n",
    "f1_test = 1-qp.error.f1e(abs_dataset.test.labels, cnn_classifier.predict(abs_dataset.test.instances))\n",
    "accuracy_test = 1-qp.error.acce(abs_dataset.test.labels, cnn_classifier.predict(abs_dataset.test.instances))\n",
    "print('- Test set:')\n",
    "print(f'\\tF1: {f1_test}')    \n",
    "print(f'\\tAccuracy: {accuracy_test}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0c873988-2b70-4de9-8af6-2863d0e55bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 15037889 - Relations: [0] - Text:\n",
      "\n",
      "\n",
      "To compare the longitudinal effects of treatment on intraocular pressure (IOP) and visual field performance in Japanese normal-tension glaucoma (NTG) between latanoprost and timolol.\n",
      "This is an open-label, randomized, study. A total of 62 NTG patients were prospectively, consecutively enrolled. All study subjects were randomly assigned to 0.005% latanoprost instillation once daily in the morning or 0.5% timolol instillation twice daily for a prospective 3-year follow-up, and underwent a routine ocular examination every month. Automated perimetry was performed every 6 months using Humphrey field analysers. Stereophotographs of optic discs were also obtained every 6 months.\n",
      "Percentage of IOP reduction or the magnitude of IOP reduction showed no intergroup differences either at any time point (13-15%). In the visual field, the estimated rate of change in the MD value (dB/year) was -0.34+/-0.17 (SE) for the latanoprost group, and -0.10+/-0.18 (SE) for the timolol group. The estimated rate of change in MD showed no significant difference from zero in both groups, and there were no statistical intergroup differences. No changes in the optic nerve head topography in the vertical cup-to-disc ratio and rim area measured by image-analysis techniques were observed in either group. There were no patients who dropped out due to the side effects of treatment regimens.\n",
      "Both latanoprost and timolol single treatments reduced IOP by 13-15% at their trough effects for 3 years in Japanese NTG patients; both showed similar effects on visual field performance.\n",
      "\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Relation Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|███████████████████████████████████████████████████| 21/21 [00:00<00:00, 20916.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tClassification:\n",
      "\t\t# Ground truth relations: (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0)\n",
      "\t\t# Predicted relations labels: [0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infer(test_set, indexer, comp_quantifier=None, comp_classifier=None, rel_quantifier=None, rel_classifier=cnn_classifier, filename=None, use_tokenizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc37da-6239-4833-9c63-03cac51fdb78",
   "metadata": {},
   "source": [
    "### 3. QuaNet \n",
    "The results are solid, let's move onto `QuaNet` training phase. `QuaNet` observes the classification predictions to learn higher-order *quantification embeddings*, which are then refined by incorporating quantification predictions of simple classify-and-count-like methods.\n",
    "\n",
    "![architecture](./images/quanet_architecture.png)\n",
    "\n",
    "The QuaNet architecture (see Figure 1) consists of two main components: a **recurrent component** and a **fully connected component**.\n",
    "\n",
    "#### 3.1 Recurrent Component: Bidirectional LSTM\n",
    "- The core of the model is a **Bidirectional LSTM** (Long Short-Term Memory), a type of recurrent neural network. \n",
    "- The LSTM receives as input a **list of pairs** $⟨Pr(c|x), \\vec{x}⟩$, where:\n",
    "  - $Pr(c|x)$ is the probability that a classifier $h$ assigns class $c$ to document $x$.\n",
    "  - $\\vec{x}$ is the **document embedding**, a vector representing the document's content.\n",
    "- The list is **sorted by the value of $Pr(c|x)$**, meaning the documents are arranged from least to most likely to belong to class $c$.\n",
    "  \n",
    "The **intuition** behind this approach is that the LSTM will \"learn to count\" positive and negative examples. By observing the ordered sequence of probabilities, the LSTM should learn to recognize the point where the documents switch from negative to positive examples. The document embedding $\\vec{x}$ helps the LSTM assign different importance to each document when making its prediction.\n",
    "\n",
    "The output of the LSTM is called a **quantification embedding**—a dense vector representing the information about the quantification task learned from the input data.\n",
    "\n",
    "#### 3.2 Fully Connected Component\n",
    "- The vector returned by the LSTM is combined with additional information, specifically **quantification-related statistics**:\n",
    "  - $\\hat{p}_c^{CC}(D)$, $\\hat{p}_c^{ACC}(D)$, $\\hat{p}_c^{PCC}(D)$, and $\\hat{p}_c^{PACC}(D)$, which are quantification predictions from different methods.\n",
    "  - $tpr_b$, $fpr_b$, $tpr_s$, and $fpr_s$, aggregate statistics related to true positive and false positive rates, which are easy to compute from the classifier $h$ using a validation set.\n",
    "\n",
    "This combined vector then passes through the second part of the architecture, which is made up of **fully connected layers** with **ReLU activations**. These layers adjust the quantification embedding using the additional statistics from the classifier to improve the accuracy of the quantification.\n",
    "\n",
    "The final output is a prediction $\\hat{p}_c^{QuaNet}(c|D)$, which represents the probability of class $c$ for the dataset $D$, produced by a **softmax layer**.\n",
    "\n",
    "QuaNet could use quantification predictions from many methods, but it focuses on those that are **computationally efficient** (like CC, ACC, PCC, and PACC). This ensures that the process remains fast while still providing sufficient information for accurate predictions.\n",
    "\n",
    "### Details\n",
    "\n",
    "| Layer | Type | Dimensions | Activation | Dropout |\n",
    "|---|---|---|---|---|\n",
    "| Input | LSTM | 128 | N/A | N/A |\n",
    "| Dense 1 | Dense | 1024 | ReLU | 0.5 |\n",
    "| Dense 2 | Dense | 512 | ReLU | 0.5 |\n",
    "| Output | Dense | 2 | Softmax | N/A |\n",
    "\n",
    "- The LSTM has **64 hidden dimensions**, and since it’s bidirectional, the final LSTM output has **128 dimensions**.\n",
    "- This LSTM output is concatenated with the **8 quantification statistics** (giving a total of 136 dimensions), which is then fed into:\n",
    "  - **Two dense layers** with **1,024** and **512 dimensions**, each using **ReLU activation** and **0.5 dropout**.\n",
    "  - Finally, the output is passed through a **softmax layer** of size 2 to make the final class prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc527bb1-dec8-4f00-b777-f3d407f93165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuaNetModule(\n",
      "  (lstm): LSTM(102, 64, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (ff_layers): ModuleList(\n",
      "    (0): Linear(in_features=136, out_features=1024, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/500 [00:00<?, ?it/s]C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\Lib\\site-packages\\quapy\\method\\_neural.py:233: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  ptrue = torch.as_tensor([sample_data.prevalence()], dtype=torch.float, device=self.device)\n",
      "[QuaNet] epoch=1 [it=499/500]\ttr-mseloss=0.02247 tr-maeloss=0.11509\tval-mseloss=-1.00000 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 85.34it/s]\n",
      "[QuaNet] epoch=2 [it=499/500]\ttr-mseloss=0.01620 tr-maeloss=0.10015\tval-mseloss=0.00939 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 98.89it/s]\n",
      "[QuaNet] epoch=3 [it=499/500]\ttr-mseloss=0.01581 tr-maeloss=0.09844\tval-mseloss=0.01178 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 94.75it/s]\n",
      "[QuaNet] epoch=4 [it=499/500]\ttr-mseloss=0.01450 tr-maeloss=0.09204\tval-mseloss=0.00923 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 88.83it/s]\n",
      "[QuaNet] epoch=5 [it=499/500]\ttr-mseloss=0.01611 tr-maeloss=0.09939\tval-mseloss=0.01475 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 96.46it/s]\n",
      "[QuaNet] epoch=6 [it=499/500]\ttr-mseloss=0.01614 tr-maeloss=0.10136\tval-mseloss=0.01312 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 91.85it/s]\n",
      "[QuaNet] epoch=7 [it=499/500]\ttr-mseloss=0.01594 tr-maeloss=0.09842\tval-mseloss=0.01354 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 86.52it/s]\n",
      "[QuaNet] epoch=8 [it=499/500]\ttr-mseloss=0.01558 tr-maeloss=0.09811\tval-mseloss=0.01257 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 89.99it/s]\n",
      "[QuaNet] epoch=9 [it=499/500]\ttr-mseloss=0.01389 tr-maeloss=0.09069\tval-mseloss=0.01351 val-maeloss=0\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 49.16it/s]\n",
      "[QuaNet] epoch=10 [it=499/500]\ttr-mseloss=0.01417 tr-maeloss=0.09422\tval-mseloss=0.01181 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 84.37it/s]\n",
      "[QuaNet] epoch=11 [it=499/500]\ttr-mseloss=0.01365 tr-maeloss=0.08972\tval-mseloss=0.01243 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 87.84it/s]\n",
      "[QuaNet] epoch=12 [it=499/500]\ttr-mseloss=0.01607 tr-maeloss=0.09894\tval-mseloss=0.01206 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 85.67it/s]\n",
      "[QuaNet] epoch=13 [it=499/500]\ttr-mseloss=0.01545 tr-maeloss=0.09988\tval-mseloss=0.00716 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 87.76it/s]\n",
      "[QuaNet] epoch=14 [it=499/500]\ttr-mseloss=0.01451 tr-maeloss=0.09323\tval-mseloss=0.00842 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 84.19it/s]\n",
      "[QuaNet] epoch=15 [it=499/500]\ttr-mseloss=0.01479 tr-maeloss=0.09581\tval-mseloss=0.01130 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 86.04it/s]\n",
      "[QuaNet] epoch=16 [it=499/500]\ttr-mseloss=0.01373 tr-maeloss=0.09366\tval-mseloss=0.01363 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 91.51it/s]\n",
      "[QuaNet] epoch=17 [it=499/500]\ttr-mseloss=0.01460 tr-maeloss=0.09355\tval-mseloss=0.01101 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 86.89it/s]\n",
      "[QuaNet] epoch=18 [it=499/500]\ttr-mseloss=0.01472 tr-maeloss=0.09427\tval-mseloss=0.01048 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 91.93it/s]\n",
      "[QuaNet] epoch=19 [it=499/500]\ttr-mseloss=0.01333 tr-maeloss=0.09268\tval-mseloss=0.00884 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 84.90it/s]\n",
      "[QuaNet] epoch=20 [it=499/500]\ttr-mseloss=0.01474 tr-maeloss=0.09694\tval-mseloss=0.00693 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 86.47it/s]\n",
      "[QuaNet] epoch=21 [it=499/500]\ttr-mseloss=0.01455 tr-maeloss=0.09478\tval-mseloss=0.01039 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 74.11it/s]\n",
      "[QuaNet] epoch=22 [it=499/500]\ttr-mseloss=0.01438 tr-maeloss=0.09556\tval-mseloss=0.01559 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 93.22it/s]\n",
      "[QuaNet] epoch=23 [it=499/500]\ttr-mseloss=0.01422 tr-maeloss=0.09286\tval-mseloss=0.01000 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 84.26it/s]\n",
      "[QuaNet] epoch=24 [it=499/500]\ttr-mseloss=0.01190 tr-maeloss=0.08559\tval-mseloss=0.01164 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 93.10it/s]\n",
      "[QuaNet] epoch=25 [it=499/500]\ttr-mseloss=0.01240 tr-maeloss=0.08773\tval-mseloss=0.01167 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 78.70it/s]\n",
      "[QuaNet] epoch=26 [it=499/500]\ttr-mseloss=0.01481 tr-maeloss=0.09532\tval-mseloss=0.00959 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 89.31it/s]\n",
      "[QuaNet] epoch=27 [it=499/500]\ttr-mseloss=0.01584 tr-maeloss=0.09834\tval-mseloss=0.01190 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 72.18it/s]\n",
      "[QuaNet] epoch=28 [it=499/500]\ttr-mseloss=0.01432 tr-maeloss=0.09689\tval-mseloss=0.01398 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 75.05it/s]\n",
      "[QuaNet] epoch=29 [it=499/500]\ttr-mseloss=0.01604 tr-maeloss=0.09824\tval-mseloss=0.01622 val-maeloss=\n",
      "100%|██████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 86.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ended by patience exhausted; loading best model parameters in ../checkpoint\\QuaNet-90930-370682-278513-222161-753977 for epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\Lib\\site-packages\\quapy\\method\\_neural.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.quanet.load_state_dict(torch.load(checkpoint))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>QuaNetTrainer(classifier__batch_size=64, classifier__batch_size_test=512,\n",
       "              classifier__device=device(type=&#x27;cpu&#x27;), classifier__drop_p=0.5,\n",
       "              classifier__embedding_size=100, classifier__epochs=200,\n",
       "              classifier__hidden_size=256, classifier__kernel_heights=[3, 5, 7],\n",
       "              classifier__lr=0.001, classifier__padding_length=300,\n",
       "              classifier__patience=10, classifier__repr_size=100,\n",
       "              classifier__stride=1, classifier__weight_decay=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;QuaNetTrainer<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>QuaNetTrainer(classifier__batch_size=64, classifier__batch_size_test=512,\n",
       "              classifier__device=device(type=&#x27;cpu&#x27;), classifier__drop_p=0.5,\n",
       "              classifier__embedding_size=100, classifier__epochs=200,\n",
       "              classifier__hidden_size=256, classifier__kernel_heights=[3, 5, 7],\n",
       "              classifier__lr=0.001, classifier__padding_length=300,\n",
       "              classifier__patience=10, classifier__repr_size=100,\n",
       "              classifier__stride=1, classifier__weight_decay=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "QuaNetTrainer(classifier__batch_size=64, classifier__batch_size_test=512,\n",
       "              classifier__device=device(type='cpu'), classifier__drop_p=0.5,\n",
       "              classifier__embedding_size=100, classifier__epochs=200,\n",
       "              classifier__hidden_size=256, classifier__kernel_heights=[3, 5, 7],\n",
       "              classifier__lr=0.001, classifier__padding_length=300,\n",
       "              classifier__patience=10, classifier__repr_size=100,\n",
       "              classifier__stride=1, classifier__weight_decay=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train QuaNet (alternatively, we can set fit_classifier=True and let QuaNet train the classifier)\n",
    "quantifier = QuaNet(cnn_classifier, qp.environ['SAMPLE_SIZE'], device='cpu')\n",
    "quantifier.fit(abs_dataset.training, fit_classifier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0de8d-011c-4c6f-bd31-62fe0c9da80e",
   "metadata": {},
   "source": [
    "We wrapped `QuaPy`'s error evaluation function and manually modified how each sample is selected; we adjusted the sampling strategy to work with batches where the batch size is equal to the number of sentences that compose each abstract. This allows us to select the entire document based on the filename associated with each sentence. We will also evaluate the results using the standard random sampling technique, where sentences from different abstracts are grouped into the same batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d8f9f37-f3ef-42c1-a148-84dffb5558f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on training set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=2)\n",
      "------------\t--------\t-----------\t-----------\n",
      "AE             \t0.0567         \t0.1781         \t0.1400         \n",
      "RAE            \t0.1601         \t0.4373         \t0.3508         \n",
      "MSE            \t0.0032         \t0.0612         \t0.0372         \n",
      "MAE            \t0.0567         \t0.1781         \t0.1400         \n",
      "MRAE           \t0.1601         \t0.4373         \t0.3508         \n",
      "MKLD           \t0.0078         \t0.1657         \t0.0797         \n",
      "\n",
      "Results on test set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=2)\n",
      "------------\t--------\t-----------\t-----------\n",
      "AE             \t0.1822         \t0.2672         \t0.2279         \n",
      "RAE            \t0.5105         \t0.8070         \t0.6694         \n",
      "MSE            \t0.0332         \t0.1067         \t0.0777         \n",
      "MAE            \t0.1822         \t0.2672         \t0.2279         \n",
      "MRAE           \t0.5105         \t0.8070         \t0.6694         \n",
      "MKLD           \t0.0686         \t0.3070         \t0.1892         \n"
     ]
    }
   ],
   "source": [
    "print('Results on training set:')\n",
    "result_train = evaluate(collection=abs_dataset.training, n=[1,2], quantifier=quantifier)\n",
    "\n",
    "print('\\nResults on test set:')\n",
    "result_test = evaluate(collection=abs_dataset.test, n=[1,2], quantifier=quantifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2784f5-4a51-4f26-aad1-ada9a77ba52d",
   "metadata": {},
   "source": [
    "The results seem promising, although the differences observed with the modified sampling strategy are substantial. This observation led us to investigate the effects of increasing the number of elements per batch, which allows us to notice a decrease in error values that tend to align more closely with the standard random sampling technique. This suggests that we might need to explore several solutions:\n",
    "\n",
    "- **Modify the Sampling Strategy During Training**: Adjusting the sampling strategy at training time could help the model learn the distribution of components within a single abstract.\n",
    "  \n",
    "- **Utilize Longer Documents**: We may consider working with longer documents containing more sentences. For instance, the [dataset suggested by Galassi](https://madoc.bib.uni-mannheim.de/46084/1/argmining-18-multi%20%289%29.pdf) contains entire papers annotated with argument components.\n",
    "\n",
    "Let’s observe how the current model behaves with some sample instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d4fcaf7-1cbd-4b79-b6de-ee445d388465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 29605574 - Relations: [0] - Text:\n",
      "Multiple studies have evaluated the hypoglycemic effect of cinnamon in patients with diabetes mellitus (DM) type II, with conflicting results. Differences in Baseline Body Mass Index (BMI) of patients may be able to explain the observed differences in the results. This study was designed to evaluate the effect of cinnamon supplementation on anthropometric, glycemic and lipid outcomes of patients with DM type II based on their baseline BMI. The study was designed as a triple-blind placebo-controlled randomized clinical trial, using a parallel design. One hundred and forty patients referred to Diabetes Clinic of Yazd University of Medical Sciences with diagnosis of DM type II were randomly assigned in four groups: cinnamon (BMI ≥ 27, BMI < 27) and Placebo (BMI ≥ 27, BMI < 27). Patients received cinnamon bark powder or placebo in 500 mg capsules twice daily for 3 months. Anthropometric, glycemic and lipid outcomes were measured before and after the intervention. Cinnamon supplementation led to improvement of all anthropometric (BMI, body fat, and visceral fat), glycemic (FPG, 2hpp, HbA1C, Fasting Insulin, and Insulin Resistance), and lipids (Cholesterol Total, LDL-c and HDL-c) outcomes (except for triglycerides level). All observed changes (except for Cholesterol Total and LDL-c) were significantly more prominent in patients with higher baseline BMI (BMI ≥ 27). Based on the study findings, cinnamon may improve anthropometric parameters, glycemic indices and lipid profile of patients with type II diabetes. These benefits are significantly more prominent in patients with higher baseline BMI (BMI ≥ 27).\n",
      "\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Relation Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|████████████████████████████████████████████████████| 10/10 [00:00<00:00, 9530.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tQuantification:\n",
      "\t\t# True distribution relations: [Class 0 = 0.8000, Class 1 = 0.2000]\n",
      "\t\t# Estimated distribution relations: [Class 0 = 0.0228, Class 1 = 0.9772]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|███████████████████████████████████████████████████| 55/55 [00:00<00:00, 27564.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Estimated distribution on tokenized relations: [Class 0 = 0.0779, Class 1 = 0.9221]\n",
      "\n",
      "\t# AE: 0.7772\n",
      "\t# RAE: 2.1980\n",
      "\t# MSE: 0.6040\n",
      "\t# MAE: 0.7772\n",
      "\t# MRAE: 2.1980\n",
      "\t# MKLD: 1.9173\n",
      "\tClassification:\n",
      "\t\t# Ground truth relations: (0, 0, 0, 0, 0, 1, 0, 0, 1, 0)\n",
      "\t\t# Predicted relations labels: [1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infer(test_set, indexer, comp_quantifier=None, comp_classifier=None, rel_quantifier=quantifier, rel_classifier=cnn_classifier, filename='29605574', use_tokenizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a2a35-fee8-4458-98ae-7708ae3f554a",
   "metadata": {},
   "source": [
    "The predictions, although not perfect, appear promising. We compute the posterior estimations in two ways: first, by using sentence tokenization applied to the dataset, taking into account the annotations provided by *Cabrio* and *Villata*; second, by simply applying `sent_tokenize()` to each abstract. The error difference between the two approaches is minimal.\n",
    "\n",
    "### 4. QuaNet with custom training routine\n",
    "\n",
    "Now, let us attempt the first of the previously proposed modifications. We have adjusted the `QuaNet` training routine so that, in each epoch, every batch contains all the sentences from an abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ec734a6-8418-4940-8c3c-7394aa58c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train QuaNet (alternatively, we can set fit_classifier=True and let QuaNet train the classifier)\n",
    "quantifier_custom = QuaNetTrainerABS(cnn_classifier, qp.environ['SAMPLE_SIZE'], device='cpu')\n",
    "quantifier_custom.fit(abs_dataset.training, fit_classifier=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d79122-4774-4458-9bb9-408c4b164847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on training set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=3)\tByDoc (n=5)\tByDoc (n=10)\tByDoc (n=13)\tByDoc (n=15)\n",
      "------------\t--------\t-----------\t-----------\t-----------\t------------\t------------\t------------\n",
      "AE             \t0.1426         \t0.1616         \t0.1423         \t0.1424         \t0.1427         \t0.1430         \t0.1426         \n",
      "RAE            \t0.2651         \t0.3329         \t0.2715         \t0.2679         \t0.2669         \t0.2675         \t0.2661         \n",
      "MSE            \t0.0203         \t0.0381         \t0.0255         \t0.0228         \t0.0217         \t0.0219         \t0.0212         \n",
      "MAE            \t0.1426         \t0.1616         \t0.1423         \t0.1424         \t0.1427         \t0.1430         \t0.1426         \n",
      "MRAE           \t0.2651         \t0.3329         \t0.2715         \t0.2679         \t0.2669         \t0.2675         \t0.2661         \n",
      "MKLD           \t0.0360         \t0.0675         \t0.0450         \t0.0403         \t0.0384         \t0.0386         \t0.0375         \n",
      "\n",
      "Results on test set:\n",
      "Error Metric\tStandard\tByDoc (n=1)\tByDoc (n=3)\tByDoc (n=5)\tByDoc (n=10)\tByDoc (n=13)\tByDoc (n=15)\n",
      "------------\t--------\t-----------\t-----------\t-----------\t------------\t------------\t------------\n",
      "AE             \t0.1360         \t0.1549         \t0.1362         \t0.1349         \t0.1361         \t0.1352         \t0.1355         \n",
      "RAE            \t0.2526         \t0.3112         \t0.2588         \t0.2541         \t0.2543         \t0.2523         \t0.2532         \n",
      "MSE            \t0.0185         \t0.0341         \t0.0236         \t0.0213         \t0.0199         \t0.0194         \t0.0196         \n",
      "MAE            \t0.1360         \t0.1549         \t0.1362         \t0.1349         \t0.1361         \t0.1352         \t0.1355         \n",
      "MRAE           \t0.2526         \t0.3112         \t0.2588         \t0.2541         \t0.2543         \t0.2523         \t0.2532         \n",
      "MKLD           \t0.0328         \t0.0603         \t0.0417         \t0.0376         \t0.0352         \t0.0343         \t0.0347         \n"
     ]
    }
   ],
   "source": [
    "print('Results on training set:')\n",
    "result_train_custom = evaluate(collection=abs_dataset.training, n=[1,3,5,10, qp.environ['SAMPLE_SIZE'], 15], quantifier=quantifier_custom)\n",
    "\n",
    "print('\\nResults on test set:')\n",
    "result_test_custom = evaluate(collection=abs_dataset.test, n=[1,3,5,10, qp.environ['SAMPLE_SIZE'], 15], quantifier=quantifier_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccbb8325-93d5-4060-8b57-40343ee1d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard QuaNet:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Labels: (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1)\n",
      "\t# Predicted labels: [0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1]\n",
      "\n",
      "\t# True distribution: [Non-components = 0.625, Components = 0.375]\n",
      "\t# Estimated distribution: [Non-components = 0.7147798538208008, Components = 0.28522008657455444]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Estimated distribution on tokenized sentences: [None = 0.7086560130119324, Components = 0.29134401679039]\n",
      "\n",
      "\t# AE: 0.0898\n",
      "\t# RAE: 0.1762\n",
      "\t# MSE: 0.0081\n",
      "\t# MAE: 0.0898\n",
      "\t# MRAE: 0.1762\n",
      "\t# MKLD: 0.0158\n",
      "Custom approach QuaNet:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Labels: (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1)\n",
      "\t# Predicted labels: [0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1]\n",
      "\n",
      "\t# True distribution: [Non-components = 0.625, Components = 0.375]\n",
      "\t# Estimated distribution: [Non-components = 0.37237972021102905, Components = 0.6276203393936157]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "indexing: 100%|████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# Estimated distribution on tokenized sentences: [None = 0.37244391441345215, Components = 0.6275560855865479]\n",
      "\n",
      "\t# AE: 0.2526\n",
      "\t# RAE: 0.4959\n",
      "\t# MSE: 0.0638\n",
      "\t# MAE: 0.2526\n",
      "\t# MRAE: 0.4959\n",
      "\t# MKLD: 0.1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filename = random.choice(test_collection.filenames)\n",
    "\n",
    "print('Standard QuaNet:')\n",
    "infer(test_set, indexer, comp_quantifier=quantifier, comp_classifier=cnn_classifier, rel_quantifier=None, filename=filename, show_text=False, use_tokenizer=True)\n",
    "\n",
    "print('Custom approach QuaNet:')\n",
    "infer(test_set, indexer, comp_quantifier=quantifier_custom, comp_classifier=cnn_classifier, rel_quantifier=None, filename=filename, show_text=False, use_tokenizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd82fb-1046-4ecf-8296-b1bdd1389223",
   "metadata": {},
   "source": [
    "Unfortunately, we observe generally higher error values with this methodology. Moreover, if we run the previous cell multiple times, we notice that the custom quantifier tends to predict an equal distribution of `Components` and `Non-components`: this might reflects the fact that, on average, both the training and test sets have a roughly equal number of argument components and non-components within each individual abstract.\n",
    "\n",
    "```python\n",
    "- Train set:\n",
    "\tLabel 0: 2760 samples\n",
    "\tLabel 1: 2593 samples\n",
    "\n",
    "\tThere are 2 different labels in the train set -> [0, 1]\n",
    "\tAverage number of sentences per file in train set: 13\n",
    "\tMax sentence length: 107\n",
    "\tAverage components per file: 6.48\n",
    "\tAverage non-components per file: 6.90\n",
    "\n",
    "- Test set:\n",
    "\tLabel 0: 1948 samples\n",
    "\tLabel 1: 1880 samples\n",
    "\n",
    "\tThere are 2 different labels in the test set -> [0, 1]\n",
    "\tAverage number of sentences per file in test set: 14\n",
    "\tMax sentence length: 91\n",
    "\tAverage components per file: 6.99\n",
    "\tAverage non-components per file: 7.24\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
